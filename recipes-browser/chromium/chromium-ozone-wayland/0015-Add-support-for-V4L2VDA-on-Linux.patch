Upstream-Status: Inappropriate

There were many attempts to upstream the same kind of patch,
but nobody succeded to do so due to some consistency problems.

We, at igalia, have been keeping this patch in downstream at
github.com/igalia/chromium in the ozone-wayland-dev branch
since M65, and constantly rebasing it. In the future, we will
try to upstream it.

Signed-off-by: Maksim Sisov <msisov@igalia.com>
---
From 7e702234cb0e0c947e04bf568acd0820d3a410e1 Mon Sep 17 00:00:00 2001
From: Maksim Sisov <msisov@igalia.com>
Date: Mon, 11 Feb 2019 11:34:34 +0200
Subject: [PATCH 15/16] Add support for V4L2VDA on Linux

This patch enables hardware assisted video decoding via the
Chromium V4L2VDA. Including changes when Linux is used. In
order to use this, use_linux_v4l2_only flag should be set
to true.

Signed-off-by: Ryo Kodama <ryo.kodama.vz@renesas.com>

fixup! avoid building not declared formats

"FRAME", "_SLICE",  "V4L2_PIX_FMT_VP9" are not defined in mainline
 Linux headers. This patch avoids building these formats.

Signed-off-by: Ryo Kodama <ryo.kodama.vz@renesas.com>

Issue #437

Change-Id: Ida0a79637f0bbf873fe206cdce21420c7ee192ca
---
 media/gpu/BUILD.gn                            | 15 ++++++++----
 media/gpu/args.gni                            |  4 ++++
 .../gpu_jpeg_decode_accelerator_factory.cc    |  3 ++-
 .../gpu_video_decode_accelerator_factory.cc   |  8 +++++++
 .../gpu_video_decode_accelerator_factory.h    |  2 ++
 media/gpu/v4l2/generic_v4l2_device.cc         |  6 ++++-
 media/gpu/v4l2/v4l2_device.cc                 | 23 +++++++++++++++++++
 .../gpu/v4l2/v4l2_video_decode_accelerator.cc |  6 ++++-
 8 files changed, 59 insertions(+), 8 deletions(-)

diff --git a/media/gpu/BUILD.gn b/media/gpu/BUILD.gn
index e939892698c4..090e92a7b4a2 100644
--- a/media/gpu/BUILD.gn
+++ b/media/gpu/BUILD.gn
@@ -16,6 +16,7 @@ buildflag_header("buildflags") {
     "USE_VAAPI=$use_vaapi",
     "USE_V4L2_CODEC=$use_v4l2_codec",
     "USE_LIBV4L2=$use_v4lplugin",
+    "USE_LINUX_V4L2=$use_linux_v4l2_only",
   ]
 }
 
@@ -23,7 +24,7 @@ if (is_mac) {
   import("//build/config/mac/mac_sdk.gni")
 }
 
-if (is_chromeos && use_v4lplugin) {
+if (use_v4lplugin) {
   action("libv4l2_generate_stubs") {
     extra_header = "v4l2/v4l2_stub_header.fragment"
 
@@ -229,17 +230,21 @@ component("gpu") {
       "v4l2/v4l2_device.h",
       "v4l2/v4l2_image_processor.cc",
       "v4l2/v4l2_image_processor.h",
-      "v4l2/v4l2_jpeg_decode_accelerator.cc",
-      "v4l2/v4l2_jpeg_decode_accelerator.h",
       "v4l2/v4l2_jpeg_encode_accelerator.cc",
       "v4l2/v4l2_jpeg_encode_accelerator.h",
-      "v4l2/v4l2_slice_video_decode_accelerator.cc",
-      "v4l2/v4l2_slice_video_decode_accelerator.h",
       "v4l2/v4l2_video_decode_accelerator.cc",
       "v4l2/v4l2_video_decode_accelerator.h",
       "v4l2/v4l2_video_encode_accelerator.cc",
       "v4l2/v4l2_video_encode_accelerator.h",
     ]
+    if (!use_linux_v4l2_only) {
+      sources += [
+        "v4l2_jpeg_decode_accelerator.cc",
+        "v4l2_jpeg_decode_accelerator.h",
+        "v4l2_slice_video_decode_accelerator.cc",
+        "v4l2_slice_video_decode_accelerator.h",
+      ]
+    }
     libs = [
       "EGL",
       "GLESv2",
diff --git a/media/gpu/args.gni b/media/gpu/args.gni
index df4b0f980ba4..ac740ffeead4 100644
--- a/media/gpu/args.gni
+++ b/media/gpu/args.gni
@@ -10,6 +10,10 @@ declare_args() {
   # platforms which have v4l2 hardware encoder / decoder.
   use_v4l2_codec = false
 
+  # Indicates that only definitions available in the mainline linux kernel
+  # will be used.
+  use_linux_v4l2_only = false
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   use_vaapi = false
diff --git a/media/gpu/gpu_jpeg_decode_accelerator_factory.cc b/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
index c0dfb52cc775..1148e752fcf4 100644
--- a/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_jpeg_decode_accelerator_factory.cc
@@ -13,7 +13,8 @@
 #include "media/gpu/buildflags.h"
 #include "media/gpu/fake_jpeg_decode_accelerator.h"
 
-#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY)
+#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY) && \
+    !BUILDFLAG(USE_LINUX_V4L2)
 #define USE_V4L2_JDA
 #endif
 
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.cc b/media/gpu/gpu_video_decode_accelerator_factory.cc
index 27b3fe4e65da..4c39f8aefa7b 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -24,7 +24,9 @@
 #endif
 #if BUILDFLAG(USE_V4L2_CODEC)
 #include "media/gpu/v4l2/v4l2_device.h"
+#if !BUILDFLAG(USE_LINUX_V4L2)
 #include "media/gpu/v4l2/v4l2_slice_video_decode_accelerator.h"
+#endif
 #include "media/gpu/v4l2/v4l2_video_decode_accelerator.h"
 #include "ui/gl/gl_surface_egl.h"
 #endif
@@ -67,10 +69,12 @@ gpu::VideoDecodeAcceleratorCapabilities GetDecoderCapabilitiesInternal(
   vda_profiles = V4L2VideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
+#if !BUILDFLAG(USE_LINUX_V4L2)
   vda_profiles = V4L2SliceVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   vda_profiles = VaapiVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
@@ -164,8 +168,10 @@ GpuVideoDecodeAcceleratorFactory::CreateVDA(
 #endif
 #if BUILDFLAG(USE_V4L2_CODEC)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
+#if !BUILDFLAG(USE_LINUX_V4L2)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA,
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
     &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
 #endif
@@ -219,6 +225,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
   return decoder;
 }
 
+#if !BUILDFLAG(USE_LINUX_V4L2)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
     const gpu::GpuDriverBugWorkarounds& workarounds,
@@ -234,6 +241,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
   return decoder;
 }
 #endif
+#endif
 
 #if BUILDFLAG(USE_VAAPI)
 std::unique_ptr<VideoDecodeAccelerator>
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.h b/media/gpu/gpu_video_decode_accelerator_factory.h
index 74f10ebeb8a2..e779ef50fcbc 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.h
+++ b/media/gpu/gpu_video_decode_accelerator_factory.h
@@ -111,11 +111,13 @@ class MEDIA_GPU_EXPORT GpuVideoDecodeAcceleratorFactory {
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences,
       MediaLog* media_log) const;
+#if !BUILDFLAG(USE_LINUX_V4L2)
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2SVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences,
       MediaLog* media_log) const;
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   std::unique_ptr<VideoDecodeAccelerator> CreateVaapiVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
diff --git a/media/gpu/v4l2/generic_v4l2_device.cc b/media/gpu/v4l2/generic_v4l2_device.cc
index a1294ae0b3c7..b22e5a703f47 100644
--- a/media/gpu/v4l2/generic_v4l2_device.cc
+++ b/media/gpu/v4l2/generic_v4l2_device.cc
@@ -477,9 +477,13 @@ bool GenericV4L2Device::OpenDevicePath(const std::string& path, Type type) {
     return false;
 
 #if BUILDFLAG(USE_LIBV4L2)
+#if BUILDFLAG(USE_LINUX_V4L2)
+  if (
+#else
   if (type == Type::kEncoder &&
+#endif
       HANDLE_EINTR(v4l2_fd_open(device_fd_.get(), V4L2_DISABLE_CONVERSION)) !=
-          -1) {
+      -1) {
     VLOGF(2) << "Using libv4l2 for " << path;
     use_libv4l2_ = true;
   }
diff --git a/media/gpu/v4l2/v4l2_device.cc b/media/gpu/v4l2/v4l2_device.cc
index c0d849ad19cd..e3c0c2fcbcb9 100644
--- a/media/gpu/v4l2/v4l2_device.cc
+++ b/media/gpu/v4l2/v4l2_device.cc
@@ -898,6 +898,19 @@ uint32_t V4L2Device::VideoFrameLayoutToV4L2PixFmt(
 }
 
 // static
+#if BUILDFLAG(USE_LINUX_V4L2)
+uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
+                                                   bool slice_based) {
+  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+    return V4L2_PIX_FMT_H264;
+  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+    return V4L2_PIX_FMT_VP8;
+  } else {
+    LOG(FATAL) << "Add more cases as needed";
+    return 0;
+  }
+}
+#else
 uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
                                                    bool slice_based) {
   if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
@@ -938,6 +951,7 @@ VideoCodecProfile V4L2Device::V4L2VP9ProfileToVideoCodecProfile(
       return VIDEO_CODEC_PROFILE_UNKNOWN;
   }
 }
+#endif
 
 // static
 std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
@@ -948,7 +962,9 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
 
   switch (pix_fmt) {
     case V4L2_PIX_FMT_H264:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_H264_SLICE:
+#endif
       if (is_encoder) {
         // TODO(posciak): need to query the device for supported H.264 profiles,
         // for now choose Main as a sensible default.
@@ -961,11 +977,14 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
       break;
 
     case V4L2_PIX_FMT_VP8:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP8_FRAME:
+#endif
       min_profile = VP8PROFILE_MIN;
       max_profile = VP8PROFILE_MAX;
       break;
 
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP9:
     case V4L2_PIX_FMT_VP9_FRAME: {
       v4l2_queryctrl query_ctrl = {};
@@ -992,6 +1011,7 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
       }
       break;
     }
+#endif
 
     default:
       VLOGF(1) << "Unhandled pixelformat " << FourccToString(pix_fmt);
@@ -1022,7 +1042,10 @@ uint32_t V4L2Device::V4L2PixFmtToDrmFormat(uint32_t format) {
       return DRM_FORMAT_ARGB8888;
 
     case V4L2_PIX_FMT_MT21C:
+#if !BUILDFLAG(USE_LINUX_V4L2)
+    case V4L2_PIX_FMT_MT21:
       return DRM_FORMAT_MT21;
+#endif
 
     default:
       DVLOGF(1) << "Unrecognized format " << FourccToString(format);
diff --git a/media/gpu/v4l2/v4l2_video_decode_accelerator.cc b/media/gpu/v4l2/v4l2_video_decode_accelerator.cc
index 0a42d8f57fa1..0ae7a9a64197 100644
--- a/media/gpu/v4l2/v4l2_video_decode_accelerator.cc
+++ b/media/gpu/v4l2/v4l2_video_decode_accelerator.cc
@@ -29,6 +29,7 @@
 #include "media/base/video_frame_layout.h"
 #include "media/base/video_types.h"
 #include "media/gpu/macros.h"
+#include "media/gpu/buildflags.h"
 #include "media/gpu/v4l2/v4l2_image_processor.h"
 #include "media/video/h264_parser.h"
 #include "ui/gfx/geometry/rect.h"
@@ -79,7 +80,10 @@ size_t GetNumPlanesOfV4L2PixFmt(uint32_t pix_fmt) {
 
 // static
 const uint32_t V4L2VideoDecodeAccelerator::supported_input_fourccs_[] = {
-    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8, V4L2_PIX_FMT_VP9,
+    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8,
+#if !BUILDFLAG(USE_LINUX_V4L2)
+    V4L2_PIX_FMT_VP9,
+#endif
 };
 
 struct V4L2VideoDecodeAccelerator::BitstreamBufferRef {
-- 
2.17.1

