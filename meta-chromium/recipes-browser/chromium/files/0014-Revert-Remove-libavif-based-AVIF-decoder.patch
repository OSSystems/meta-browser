From 75e1653ce9bf360e4c1cb5b86872ebff0b67a35b Mon Sep 17 00:00:00 2001
From: Ariel D'Alessandro <ariel.dalessandro@collabora.com>
Date: Thu, 17 Jul 2025 12:51:22 -0300
Subject: [PATCH] Revert "Remove libavif based AVIF decoder"

This reverts commit ce78002f97a433e53ab16805e16b895f9b52ea24.

In order to disable crabbyavif to fix build errors, re-enable libavif so
it can be used in replacement.

Upstream-Status: Inappropriate [upstream ticket https://crbug.com/357017325]
Signed-off-by: Ariel D'Alessandro <ariel.dalessandro@collabora.com>
---
 .../common/ProductionSupportedFlagList.java   |    3 +
 chrome/browser/about_flags.cc                 |    4 +
 chrome/browser/flag-metadata.json             |    5 +
 chrome/browser/flag_descriptions.cc           |    5 +
 chrome/browser/flag_descriptions.h            |    3 +
 third_party/blink/common/features.cc          |    2 +
 third_party/blink/public/common/features.h    |    3 +
 third_party/blink/renderer/platform/BUILD.gn  |   13 +
 .../renderer/platform/image-decoders/BUILD.gn |   12 +-
 .../image-decoders/avif/avif_image_decoder.cc | 1295 ++++++++++++
 .../image-decoders/avif/avif_image_decoder.h  |  191 ++
 .../avif/avif_image_decoder_fuzzer.cc         |   30 +
 .../avif/avif_image_decoder_test.cc           | 1758 +++++++++++++++++
 .../avif/gen_crabbyavif_wrapper.py            |  164 ++
 .../platform/image-decoders/image_decoder.cc  |   17 +-
 .../image_decoder_fuzzer_utils.cc             |    8 +
 .../image_decoder_fuzzer_utils.h              |    1 +
 17 files changed, 3508 insertions(+), 6 deletions(-)
 create mode 100644 third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.cc
 create mode 100644 third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h
 create mode 100644 third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_fuzzer.cc
 create mode 100644 third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_test.cc
 create mode 100644 third_party/blink/renderer/platform/image-decoders/avif/gen_crabbyavif_wrapper.py

diff --git a/android_webview/java/src/org/chromium/android_webview/common/ProductionSupportedFlagList.java b/android_webview/java/src/org/chromium/android_webview/common/ProductionSupportedFlagList.java
index def02f59887c1..3bfa4dc335cb1 100644
--- a/android_webview/java/src/org/chromium/android_webview/common/ProductionSupportedFlagList.java
+++ b/android_webview/java/src/org/chromium/android_webview/common/ProductionSupportedFlagList.java
@@ -434,6 +434,9 @@ public final class ProductionSupportedFlagList {
         Flag.baseFeature(
                 BaseFeatures.RUN_TASKS_BY_BATCHES,
                 "Run tasks in queue for 8ms before before sending a system message."),
+        Flag.baseFeature(
+                BlinkFeatures.CRABBY_AVIF,
+                "If enabled, CrabbyAvif will be used instead of libavif for decoding AVIF images."),
         Flag.baseFeature(
                 NetworkServiceFeatures.DEPRECATE_UNLOAD,
                 "If false prevents the gradual deprecation of the unload event."),
diff --git a/chrome/browser/about_flags.cc b/chrome/browser/about_flags.cc
index 5156e5d3f2c74..1a0e2039bda1d 100644
--- a/chrome/browser/about_flags.cc
+++ b/chrome/browser/about_flags.cc
@@ -7780,6 +7780,10 @@ const FeatureEntry kFeatureEntries[] = {
      flag_descriptions::kAvifGainmapHdrImagesDescription, kOsAll,
      FEATURE_VALUE_TYPE(blink::features::kAvifGainmapHdrImages)},

+    {"crabbyavif", flag_descriptions::kCrabbyAvifName,
+     flag_descriptions::kCrabbyAvifDescription, kOsAll,
+     FEATURE_VALUE_TYPE(blink::features::kCrabbyAvif)},
+
     {"file-handling-icons", flag_descriptions::kFileHandlingIconsName,
      flag_descriptions::kFileHandlingIconsDescription, kOsDesktop,
      FEATURE_VALUE_TYPE(blink::features::kFileHandlingIcons)},
diff --git a/chrome/browser/flag-metadata.json b/chrome/browser/flag-metadata.json
index d6851e527feb1..bd09150e90221 100644
--- a/chrome/browser/flag-metadata.json
+++ b/chrome/browser/flag-metadata.json
@@ -1658,6 +1658,11 @@
     "owners": ["sebsg@chromium.org", "bling-transactions-eng@google.com"],
     "expiry_milestone": 135
   },
+  {
+    "name": "crabbyavif",
+    "owners": [ "vigneshv@google.com", "image-codecs-eng@google.com" ],
+    "expiry_milestone": 133
+  },
   {
     "name": "cras-processor-wav-dump",
     "owners": ["aaronyu@google.com", "chromeos-audio@google.com" ],
diff --git a/chrome/browser/flag_descriptions.cc b/chrome/browser/flag_descriptions.cc
index c06c6c65b1398..1050fe6c31ca1 100644
--- a/chrome/browser/flag_descriptions.cc
+++ b/chrome/browser/flag_descriptions.cc
@@ -446,6 +446,11 @@ const char kAvifGainmapHdrImagesDescription[] =
     "If enabled, Chrome uses the gainmap (if present) in AVIF images to render "
     "the HDR version on HDR displays and the SDR version on SDR displays.";

+const char kCrabbyAvifName[] = "CrabbyAvif for decoding AVIF images";
+const char kCrabbyAvifDescription[] =
+    "If enabled, CrabbyAvif will be used instead of libavif for decoding AVIF "
+    "images";
+
 const char kTangibleSyncName[] = "Tangible Sync";
 const char kTangibleSyncDescription[] =
     "Enables the tangible sync when a user starts the sync consent flow";
diff --git a/chrome/browser/flag_descriptions.h b/chrome/browser/flag_descriptions.h
index be3f7a6e96f05..0e4e01f106ba8 100644
--- a/chrome/browser/flag_descriptions.h
+++ b/chrome/browser/flag_descriptions.h
@@ -312,6 +312,9 @@ extern const char kForestFeatureDescription[];
 extern const char kAvifGainmapHdrImagesName[];
 extern const char kAvifGainmapHdrImagesDescription[];

+extern const char kCrabbyAvifName[];
+extern const char kCrabbyAvifDescription[];
+
 extern const char kTangibleSyncName[];
 extern const char kTangibleSyncDescription[];

diff --git a/third_party/blink/common/features.cc b/third_party/blink/common/features.cc
index 720c38313bd13..e4d60ff6ade3e 100644
--- a/third_party/blink/common/features.cc
+++ b/third_party/blink/common/features.cc
@@ -510,6 +510,8 @@ BASE_FEATURE(kCorrectFloatExtensionTestForWebGL,
              "CorrectFloatExtensionTestForWebGL",
              base::FEATURE_ENABLED_BY_DEFAULT);

+BASE_FEATURE(kCrabbyAvif, "CrabbyAvif", base::FEATURE_ENABLED_BY_DEFAULT);
+
 // When enabled, add a new option, {imageOrientation: 'none'}, to
 // createImageBitmap, which ignores the image orientation metadata of the source
 // and renders the image as encoded.
diff --git a/third_party/blink/public/common/features.h b/third_party/blink/public/common/features.h
index 9970347ef0ccb..220f447a0725e 100644
--- a/third_party/blink/public/common/features.h
+++ b/third_party/blink/public/common/features.h
@@ -366,6 +366,9 @@ BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE_PARAM(
 // See http://crbug.com/40788570.
 BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kDevToolsImprovedNetworkError);

+// Enables the use of CrabbyAvif for decoding AVIF images.
+BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kCrabbyAvif);
+
 // Enables input IPC to directly target the renderer's compositor thread without
 // hopping through the IO thread first.
 BLINK_COMMON_EXPORT BASE_DECLARE_FEATURE(kDirectCompositorThreadIpc);
diff --git a/third_party/blink/renderer/platform/BUILD.gn b/third_party/blink/renderer/platform/BUILD.gn
index 291676c658372..57505f9d2622c 100644
--- a/third_party/blink/renderer/platform/BUILD.gn
+++ b/third_party/blink/renderer/platform/BUILD.gn
@@ -2786,6 +2786,19 @@ fuzzer_test("web_icon_sizes_fuzzer") {
   additional_configs = [ "//third_party/blink/renderer:inside_blink" ]
 }

+# Fuzzer for blink::AVIFImageDecoder
+fuzzer_test("blink_avif_decoder_fuzzer") {
+  sources = [ "image-decoders/avif/avif_image_decoder_fuzzer.cc" ]
+  deps = [
+    ":blink_fuzzer_test_support",
+    ":blink_image_decoder_fuzzer_test_support",
+    ":platform",
+  ]
+  seed_corpuses = [ "//third_party/blink/web_tests/images/resources/avif" ]
+  libfuzzer_options = [ "rss_limit_mb=8192" ]
+  additional_configs = [ "//third_party/blink/renderer:inside_blink" ]
+}
+
 # Fuzzer for blink::CrabbyAVIFImageDecoder
 fuzzer_test("blink_crabbyavif_decoder_fuzzer") {
   sources = [ "image-decoders/avif/crabbyavif_image_decoder_fuzzer.cc" ]
diff --git a/third_party/blink/renderer/platform/image-decoders/BUILD.gn b/third_party/blink/renderer/platform/image-decoders/BUILD.gn
index 870c7e8537249..e638c6bfcd93a 100644
--- a/third_party/blink/renderer/platform/image-decoders/BUILD.gn
+++ b/third_party/blink/renderer/platform/image-decoders/BUILD.gn
@@ -79,11 +79,16 @@ component("image_decoders") {

   if (enable_av1_decoder) {
     sources += [
+      "avif/avif_image_decoder.cc",
+      "avif/avif_image_decoder.h",
       "avif/crabbyavif_image_decoder.cc",
       "avif/crabbyavif_image_decoder.h",
     ]

-    deps += [ "//third_party/crabbyavif" ]
+    deps += [
+      "//third_party/crabbyavif",
+      "//third_party/libavif",
+    ]
   }

   if (enable_rust_png) {
@@ -130,6 +135,9 @@ source_set("unit_tests") {
   }

   if (enable_av1_decoder) {
-    sources += [ "avif/crabbyavif_image_decoder_test.cc" ]
+    sources += [
+      "avif/avif_image_decoder_test.cc",
+      "avif/crabbyavif_image_decoder_test.cc",
+    ]
   }
 }
diff --git a/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.cc b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.cc
new file mode 100644
index 0000000000000..eb9448d06d30a
--- /dev/null
+++ b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.cc
@@ -0,0 +1,1295 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifdef UNSAFE_BUFFERS_BUILD
+// TODO(crbug.com/351564777): Remove this and convert code to safer constructs.
+#pragma allow_unsafe_buffers
+#endif
+
+#include "third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h"
+
+#include <stdint.h>
+#include <string.h>
+
+#include <algorithm>
+#include <array>
+#include <memory>
+#include <optional>
+#include <utility>
+
+#include "base/bits.h"
+#include "base/containers/adapters.h"
+#include "base/feature_list.h"
+#include "base/functional/bind.h"
+#include "base/logging.h"
+#include "base/memory/scoped_refptr.h"
+#include "base/metrics/histogram_functions.h"
+#include "base/numerics/safe_conversions.h"
+#include "base/timer/elapsed_timer.h"
+#include "build/build_config.h"
+#include "cc/base/math_util.h"
+#include "media/base/video_color_space.h"
+#include "skia/ext/cicp.h"
+#include "third_party/blink/public/common/features.h"
+#include "third_party/blink/renderer/platform/image-decoders/fast_shared_buffer_reader.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_animation.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_decoder.h"
+#include "third_party/blink/renderer/platform/image-decoders/rw_buffer.h"
+#include "third_party/libavif/src/include/avif/avif.h"
+#include "third_party/libyuv/include/libyuv.h"
+#include "third_party/skia/include/core/SkColorSpace.h"
+#include "third_party/skia/include/core/SkTypes.h"
+#include "third_party/skia/include/private/SkXmp.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/icc_profile.h"
+
+#if defined(ARCH_CPU_BIG_ENDIAN)
+#error Blink assumes a little-endian target.
+#endif
+
+namespace blink {
+
+namespace {
+
+// The maximum AVIF file size we are willing to decode. This helps libavif
+// detect invalid sizes and offsets in an AVIF file before the file size is
+// known.
+constexpr uint64_t kMaxAvifFileSize = 0x10000000;  // 256 MB
+
+const char* AvifDecoderErrorMessage(const avifDecoder* decoder) {
+  // decoder->diag.error is a char array that stores a null-terminated C string.
+  return *decoder->diag.error != '\0' ? decoder->diag.error
+                                      : "(no error message)";
+}
+
+// Builds a gfx::ColorSpace from the ITU-T H.273 (CICP) color description.
+gfx::ColorSpace GetColorSpace(
+    avifColorPrimaries color_primaries,
+    avifTransferCharacteristics transfer_characteristics,
+    avifMatrixCoefficients matrix_coefficients,
+    avifRange yuv_range,
+    bool grayscale) {
+  // (As of ISO/IEC 23000-22:2019 Amendment 2) MIAF Section 7.3.6.4 says:
+  //   If a coded image has no associated colour property, the default property
+  //   is defined as having colour_type equal to 'nclx' with properties as
+  //   follows:
+  //   – colour_primaries equal to 1,
+  //   - transfer_characteristics equal to 13,
+  //   - matrix_coefficients equal to 5 or 6 (which are functionally identical),
+  //     and
+  //   - full_range_flag equal to 1.
+  //   ...
+  // These values correspond to AVIF_COLOR_PRIMARIES_BT709,
+  // AVIF_TRANSFER_CHARACTERISTICS_SRGB, and AVIF_MATRIX_COEFFICIENTS_BT601,
+  // respectively.
+  //
+  // Note that this only specifies the default color property when the color
+  // property is absent. It does not really specify the default values for
+  // colour_primaries, transfer_characteristics, and matrix_coefficients when
+  // they are equal to 2 (unspecified). But we will interpret it as specifying
+  // the default values for these variables because we must choose some defaults
+  // and these are the most reasonable defaults to choose. We also advocate that
+  // all AVIF decoders choose these defaults:
+  // https://github.com/AOMediaCodec/av1-avif/issues/84
+  const auto primaries = color_primaries == AVIF_COLOR_PRIMARIES_UNSPECIFIED
+                             ? AVIF_COLOR_PRIMARIES_BT709
+                             : color_primaries;
+  const auto transfer =
+      transfer_characteristics == AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED
+          ? AVIF_TRANSFER_CHARACTERISTICS_SRGB
+          : transfer_characteristics;
+  const auto matrix =
+      (grayscale || matrix_coefficients == AVIF_MATRIX_COEFFICIENTS_UNSPECIFIED)
+          ? AVIF_MATRIX_COEFFICIENTS_BT601
+          : matrix_coefficients;
+  const auto range = yuv_range == AVIF_RANGE_FULL
+                         ? gfx::ColorSpace::RangeID::FULL
+                         : gfx::ColorSpace::RangeID::LIMITED;
+  media::VideoColorSpace color_space(primaries, transfer, matrix, range);
+  if (color_space.IsSpecified()) {
+    return color_space.ToGfxColorSpace();
+  }
+  // media::VideoColorSpace and gfx::ColorSpace do not support CICP
+  // MatrixCoefficients 12, 13, 14.
+  DCHECK_GE(matrix, 12);
+  DCHECK_LE(matrix, 14);
+  if (yuv_range == AVIF_RANGE_FULL) {
+    return gfx::ColorSpace::CreateJpeg();
+  }
+  return gfx::ColorSpace::CreateREC709();
+}
+
+// Builds a gfx::ColorSpace from the ITU-T H.273 (CICP) color description in the
+// image.
+gfx::ColorSpace GetColorSpace(const avifImage* image) {
+  const bool grayscale = image->yuvFormat == AVIF_PIXEL_FORMAT_YUV400;
+  return GetColorSpace(image->colorPrimaries, image->transferCharacteristics,
+                       image->matrixCoefficients, image->yuvRange, grayscale);
+}
+
+// |y_size| is the width or height of the Y plane. Returns the width or height
+// of the U and V planes. |chroma_shift| represents the subsampling of the
+// chroma (U and V) planes in the x (for width) or y (for height) direction.
+int UVSize(int y_size, int chroma_shift) {
+  DCHECK(chroma_shift == 0 || chroma_shift == 1);
+  return (y_size + chroma_shift) >> chroma_shift;
+}
+
+float FractionToFloat(auto numerator, uint32_t denominator) {
+  // First cast to double and not float because uint32_t->float conversion can
+  // cause precision loss.
+  return static_cast<double>(numerator) / denominator;
+}
+
+// If the image has a gain map, returns the alternate image's color space, if
+// it's different from the base image's and can be converted to a SkColorSpace.
+// If the alternate image color space is the same as the base image, there is no
+// need to specify it in SkGainmapInfo, and using the base image's color space
+// may be more accurate if the profile cannot be exactly represented as a
+// SkColorSpace object.
+sk_sp<SkColorSpace> GetAltImageColorSpace(const avifImage& image) {
+  const avifGainMap* gain_map = image.gainMap;
+  if (!gain_map) {
+    return nullptr;
+  }
+  sk_sp<SkColorSpace> color_space;
+  if (gain_map->altICC.size) {
+    if (image.icc.size == gain_map->altICC.size &&
+        memcmp(gain_map->altICC.data, image.icc.data, gain_map->altICC.size) ==
+            0) {
+      // Same ICC as the base image, no need to specify it.
+      return nullptr;
+    }
+    std::unique_ptr<ColorProfile> profile = ColorProfile::Create(
+        base::span(gain_map->altICC.data, gain_map->altICC.size));
+    if (!profile) {
+      DVLOG(1) << "Failed to parse gain map ICC profile";
+      return nullptr;
+    }
+    const skcms_ICCProfile* icc_profile = profile->GetProfile();
+    if (icc_profile->has_CICP) {
+      color_space =
+          skia::CICPGetSkColorSpace(icc_profile->CICP.color_primaries,
+                                    icc_profile->CICP.transfer_characteristics,
+                                    icc_profile->CICP.matrix_coefficients,
+                                    icc_profile->CICP.video_full_range_flag,
+                                    /*prefer_srgb_trfn=*/true);
+    } else if (icc_profile->has_toXYZD50) {
+      // The transfer function is irrelevant for gain map tone mapping,
+      // set it to something standard in case it's not set or not
+      // supported.
+      skcms_ICCProfile with_srgb = *icc_profile;
+      skcms_SetTransferFunction(&with_srgb, skcms_sRGB_TransferFunction());
+      color_space = SkColorSpace::Make(with_srgb);
+    }
+  } else if (gain_map->altColorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED) {
+    if (image.icc.size == 0 &&
+        image.colorPrimaries == gain_map->altColorPrimaries) {
+      // Same as base image, no need to specify it.
+      return nullptr;
+    }
+    const bool grayscale = (gain_map->altPlaneCount == 1);
+    const gfx::ColorSpace alt_color_space = GetColorSpace(
+        gain_map->altColorPrimaries, gain_map->altTransferCharacteristics,
+        gain_map->altMatrixCoefficients, gain_map->altYUVRange, grayscale);
+    color_space = alt_color_space.GetAsFullRangeRGB().ToSkColorSpace();
+  }
+
+  if (!color_space) {
+    DVLOG(1) << "Gain map image contains an unsupported color space";
+  }
+
+  return color_space;
+}
+
+}  // namespace
+
+AVIFImageDecoder::AVIFImageDecoder(AlphaOption alpha_option,
+                                   HighBitDepthDecodingOption hbd_option,
+                                   ColorBehavior color_behavior,
+                                   cc::AuxImage aux_image,
+                                   wtf_size_t max_decoded_bytes,
+                                   AnimationOption animation_option)
+    : ImageDecoder(alpha_option,
+                   hbd_option,
+                   color_behavior,
+                   aux_image,
+                   max_decoded_bytes),
+      animation_option_(animation_option) {}
+
+AVIFImageDecoder::~AVIFImageDecoder() = default;
+
+String AVIFImageDecoder::FilenameExtension() const {
+  return "avif";
+}
+
+const AtomicString& AVIFImageDecoder::MimeType() const {
+  DEFINE_STATIC_LOCAL(const AtomicString, avif_mime_type, ("image/avif"));
+  return avif_mime_type;
+}
+
+bool AVIFImageDecoder::ImageIsHighBitDepth() {
+  return bit_depth_ > 8;
+}
+
+void AVIFImageDecoder::OnSetData(scoped_refptr<SegmentReader> data) {
+  have_parsed_current_data_ = false;
+  const bool all_data_received = IsAllDataReceived();
+  avif_io_data_.reader = data_;
+  avif_io_data_.all_data_received = all_data_received;
+  avif_io_.sizeHint = all_data_received ? data_->size() : kMaxAvifFileSize;
+
+  // ImageFrameGenerator::GetYUVAInfo() and ImageFrameGenerator::DecodeToYUV()
+  // assume that allow_decode_to_yuv_ and other image metadata are available
+  // after calling ImageDecoder::Create() with data_complete=true.
+  if (all_data_received) {
+    ParseMetadata();
+  }
+}
+
+cc::YUVSubsampling AVIFImageDecoder::GetYUVSubsampling() const {
+  switch (avif_yuv_format_) {
+    case AVIF_PIXEL_FORMAT_YUV420:
+      return cc::YUVSubsampling::k420;
+    case AVIF_PIXEL_FORMAT_YUV422:
+      return cc::YUVSubsampling::k422;
+    case AVIF_PIXEL_FORMAT_YUV444:
+      return cc::YUVSubsampling::k444;
+    case AVIF_PIXEL_FORMAT_YUV400:
+      return cc::YUVSubsampling::kUnknown;
+    case AVIF_PIXEL_FORMAT_NONE:
+      // avif_yuv_format_ is initialized to AVIF_PIXEL_FORMAT_NONE in the
+      // constructor. If we have called SetSize() successfully at the end
+      // of UpdateDemuxer(), avif_yuv_format_ cannot possibly be
+      // AVIF_PIXEL_FORMAT_NONE.
+      CHECK(!IsDecodedSizeAvailable());
+      return cc::YUVSubsampling::kUnknown;
+    default:
+      break;
+  }
+  NOTREACHED() << "Invalid YUV format: " << avif_yuv_format_;
+}
+
+gfx::Size AVIFImageDecoder::DecodedYUVSize(cc::YUVIndex index) const {
+  DCHECK(IsDecodedSizeAvailable());
+  if (index == cc::YUVIndex::kU || index == cc::YUVIndex::kV) {
+    return gfx::Size(UVSize(Size().width(), chroma_shift_x_),
+                     UVSize(Size().height(), chroma_shift_y_));
+  }
+  return Size();
+}
+
+wtf_size_t AVIFImageDecoder::DecodedYUVWidthBytes(cc::YUVIndex index) const {
+  DCHECK(IsDecodedSizeAvailable());
+  // Try to return the same width bytes as used by the dav1d library. This will
+  // allow DecodeToYUV() to copy each plane with a single memcpy() call.
+  //
+  // The comments for Dav1dPicAllocator in dav1d/picture.h require the pixel
+  // width be padded to a multiple of 128 pixels.
+  wtf_size_t aligned_width = static_cast<wtf_size_t>(
+      base::bits::AlignUpDeprecatedDoNotUse(Size().width(), 128));
+  if (index == cc::YUVIndex::kU || index == cc::YUVIndex::kV) {
+    aligned_width >>= chroma_shift_x_;
+  }
+  // When the stride is a multiple of 1024, dav1d_default_picture_alloc()
+  // slightly pads the stride to avoid a reduction in cache hit rate in most
+  // L1/L2 cache implementations. Match that trick here. (Note that this padding
+  // is not documented in dav1d/picture.h.)
+  if ((aligned_width & 1023) == 0) {
+    aligned_width += 64;
+  }
+
+  // High bit depth YUV is stored as a uint16_t, double the number of bytes.
+  if (bit_depth_ > 8) {
+    DCHECK_LE(bit_depth_, 16);
+    aligned_width *= 2;
+  }
+
+  return aligned_width;
+}
+
+SkYUVColorSpace AVIFImageDecoder::GetYUVColorSpace() const {
+  DCHECK(CanDecodeToYUV());
+  DCHECK_NE(yuv_color_space_, SkYUVColorSpace::kIdentity_SkYUVColorSpace);
+  return yuv_color_space_;
+}
+
+uint8_t AVIFImageDecoder::GetYUVBitDepth() const {
+  DCHECK(CanDecodeToYUV());
+  return bit_depth_;
+}
+
+std::optional<gfx::HDRMetadata> AVIFImageDecoder::GetHDRMetadata() const {
+  return hdr_metadata_;
+}
+
+void AVIFImageDecoder::DecodeToYUV() {
+  DCHECK(image_planes_);
+  DCHECK(CanDecodeToYUV());
+
+  if (Failed()) {
+    return;
+  }
+
+  DCHECK(decoder_);
+  DCHECK_EQ(decoded_frame_count_, 1u);  // Not animation.
+
+  // If the image is decoded progressively, just render the highest progressive
+  // frame in image_planes_ because the callers of DecodeToYUV() assume that a
+  // complete scan will not be updated.
+  const int frame_index = progressive_ ? (decoder_->imageCount - 1) : 0;
+  // TODO(crbug.com/943519): Implement YUV incremental decoding as in Decode().
+  decoder_->allowIncremental = AVIF_FALSE;
+
+  // libavif cannot decode to an external buffer. So we need to copy from
+  // libavif's internal buffer to |image_planes_|.
+  // TODO(crbug.com/1099825): Enhance libavif to decode to an external buffer.
+  auto ret = DecodeImage(frame_index);
+  if (ret != AVIF_RESULT_OK) {
+    if (ret != AVIF_RESULT_WAITING_ON_IO) {
+      SetFailed();
+    }
+    return;
+  }
+  const avifImage* image = decoded_image_;
+
+  DCHECK(!image->alphaPlane);
+  static_assert(cc::YUVIndex::kY == static_cast<cc::YUVIndex>(AVIF_CHAN_Y), "");
+  static_assert(cc::YUVIndex::kU == static_cast<cc::YUVIndex>(AVIF_CHAN_U), "");
+  static_assert(cc::YUVIndex::kV == static_cast<cc::YUVIndex>(AVIF_CHAN_V), "");
+
+  // Disable subnormal floats which can occur when converting to half float.
+  std::unique_ptr<cc::ScopedSubnormalFloatDisabler> disable_subnormals;
+  const bool is_f16 = image_planes_->color_type() == kA16_float_SkColorType;
+  if (is_f16) {
+    disable_subnormals = std::make_unique<cc::ScopedSubnormalFloatDisabler>();
+  }
+  const float kHighBitDepthMultiplier =
+      (is_f16 ? 1.0f : 65535.0f) / ((1 << bit_depth_) - 1);
+
+  // Initialize |width| and |height| to the width and height of the luma plane.
+  uint32_t width = image->width;
+  uint32_t height = image->height;
+
+  for (wtf_size_t plane_index = 0; plane_index < cc::kNumYUVPlanes;
+       ++plane_index) {
+    const cc::YUVIndex plane = static_cast<cc::YUVIndex>(plane_index);
+    const wtf_size_t src_row_bytes =
+        base::strict_cast<wtf_size_t>(image->yuvRowBytes[plane_index]);
+    const wtf_size_t dst_row_bytes = image_planes_->RowBytes(plane);
+
+    if (bit_depth_ == 8) {
+      DCHECK_EQ(image_planes_->color_type(), kGray_8_SkColorType);
+      const uint8_t* src = image->yuvPlanes[plane_index];
+      uint8_t* dst = static_cast<uint8_t*>(image_planes_->Plane(plane));
+      libyuv::CopyPlane(src, src_row_bytes, dst, dst_row_bytes, width, height);
+    } else {
+      DCHECK_GT(bit_depth_, 8u);
+      DCHECK_LE(bit_depth_, 16u);
+      const uint16_t* src =
+          reinterpret_cast<uint16_t*>(image->yuvPlanes[plane_index]);
+      uint16_t* dst = static_cast<uint16_t*>(image_planes_->Plane(plane));
+      if (image_planes_->color_type() == kA16_unorm_SkColorType) {
+        const wtf_size_t src_stride = src_row_bytes / 2;
+        const wtf_size_t dst_stride = dst_row_bytes / 2;
+        for (uint32_t j = 0; j < height; ++j) {
+          for (uint32_t i = 0; i < width; ++i) {
+            dst[j * dst_stride + i] =
+                src[j * src_stride + i] * kHighBitDepthMultiplier + 0.5f;
+          }
+        }
+      } else if (image_planes_->color_type() == kA16_float_SkColorType) {
+        // Note: Unlike CopyPlane_16, HalfFloatPlane wants the stride in bytes.
+        libyuv::HalfFloatPlane(src, src_row_bytes, dst, dst_row_bytes,
+                               kHighBitDepthMultiplier, width, height);
+      } else {
+        NOTREACHED() << "Unsupported color type: "
+                     << static_cast<int>(image_planes_->color_type());
+      }
+    }
+    if (plane == cc::YUVIndex::kY) {
+      // Having processed the luma plane, change |width| and |height| to the
+      // width and height of the chroma planes.
+      width = UVSize(width, chroma_shift_x_);
+      height = UVSize(height, chroma_shift_y_);
+    }
+  }
+  image_planes_->SetHasCompleteScan();
+}
+
+int AVIFImageDecoder::RepetitionCount() const {
+  if (decoded_frame_count_ > 1) {
+    switch (decoder_->repetitionCount) {
+      case AVIF_REPETITION_COUNT_INFINITE:
+        return kAnimationLoopInfinite;
+      case AVIF_REPETITION_COUNT_UNKNOWN:
+        // The AVIF file does not have repetitions specified using an EditList
+        // box. Loop infinitely for backward compatibility with older versions
+        // of Chrome.
+        return kAnimationLoopInfinite;
+      default:
+        return decoder_->repetitionCount;
+    }
+  }
+  return kAnimationNone;
+}
+
+bool AVIFImageDecoder::FrameIsReceivedAtIndex(wtf_size_t index) const {
+  if (!IsDecodedSizeAvailable()) {
+    return false;
+  }
+  if (decoded_frame_count_ == 1) {
+    return ImageDecoder::FrameIsReceivedAtIndex(index);
+  }
+  if (index >= frame_buffer_cache_.size()) {
+    return false;
+  }
+  if (IsAllDataReceived()) {
+    return true;
+  }
+  avifExtent data_extent;
+  if (avifDecoderNthImageMaxExtent(decoder_.get(), index, &data_extent) !=
+      AVIF_RESULT_OK) {
+    return false;
+  }
+  return data_extent.size == 0 ||
+         data_extent.offset + data_extent.size <= data_->size();
+}
+
+std::optional<base::TimeDelta> AVIFImageDecoder::FrameTimestampAtIndex(
+    wtf_size_t index) const {
+  return index < frame_buffer_cache_.size()
+             ? frame_buffer_cache_[index].Timestamp()
+             : std::nullopt;
+}
+
+base::TimeDelta AVIFImageDecoder::FrameDurationAtIndex(wtf_size_t index) const {
+  return index < frame_buffer_cache_.size()
+             ? frame_buffer_cache_[index].Duration()
+             : base::TimeDelta();
+}
+
+bool AVIFImageDecoder::ImageHasBothStillAndAnimatedSubImages() const {
+  // Per MIAF, all animated AVIF files must have a still image, even if it's
+  // just a pointer to the first frame of the animation.
+  return decoder_ && decoder_->imageSequenceTrackPresent;
+}
+
+// static
+bool AVIFImageDecoder::MatchesAVIFSignature(
+    const FastSharedBufferReader& fast_reader) {
+  // avifPeekCompatibleFileType() clamps compatible brands at 32 when reading in
+  // the ftyp box in ISO BMFF for the 'avif' or 'avis' brand. So the maximum
+  // number of bytes read is 144 bytes (size 4 bytes, type 4 bytes, major brand
+  // 4 bytes, minor version 4 bytes, and 4 bytes * 32 compatible brands).
+  char buffer[144];
+  avifROData input;
+  input.size = std::min(sizeof(buffer), fast_reader.size());
+  input.data = reinterpret_cast<const uint8_t*>(
+      fast_reader.GetConsecutiveData(0, input.size, buffer));
+  return avifPeekCompatibleFileType(&input);
+}
+
+gfx::ColorSpace AVIFImageDecoder::GetColorSpaceForTesting() const {
+  const auto* image = GetDecoderImage();
+  CHECK(image);
+  return GetColorSpace(image);
+}
+
+void AVIFImageDecoder::ParseMetadata() {
+  if (!UpdateDemuxer()) {
+    SetFailed();
+  }
+}
+
+void AVIFImageDecoder::DecodeSize() {
+  ParseMetadata();
+}
+
+wtf_size_t AVIFImageDecoder::DecodeFrameCount() {
+  if (!Failed()) {
+    ParseMetadata();
+  }
+  return IsDecodedSizeAvailable() ? decoded_frame_count_
+                                  : frame_buffer_cache_.size();
+}
+
+void AVIFImageDecoder::InitializeNewFrame(wtf_size_t index) {
+  auto& buffer = frame_buffer_cache_[index];
+  if (decode_to_half_float_) {
+    buffer.SetPixelFormat(ImageFrame::PixelFormat::kRGBA_F16);
+  }
+
+  // For AVIFs, the frame always fills the entire image.
+  buffer.SetOriginalFrameRect(gfx::Rect(Size()));
+
+  avifImageTiming timing;
+  auto ret = avifDecoderNthImageTiming(decoder_.get(), index, &timing);
+  DCHECK_EQ(ret, AVIF_RESULT_OK);
+  buffer.SetTimestamp(base::Seconds(timing.pts));
+  buffer.SetDuration(base::Seconds(timing.duration));
+}
+
+void AVIFImageDecoder::Decode(wtf_size_t index) {
+  if (Failed()) {
+    return;
+  }
+
+  UpdateAggressivePurging(index);
+
+  int frame_index = index;
+  // If the image is decoded progressively, find the highest progressive
+  // frame that we have received and decode from that frame index. Internally
+  // decoder_ still decodes the lower progressive frames, but they are only used
+  // as reference frames and not rendered.
+  if (progressive_) {
+    DCHECK_EQ(index, 0u);
+    // decoder_->imageIndex is the current image index. decoder_->imageIndex is
+    // initialized to -1. decoder_->imageIndex + 1 is the next image index.
+    DCHECK_LT(decoder_->imageIndex + 1, decoder_->imageCount);
+    for (frame_index = decoder_->imageIndex + 1;
+         frame_index + 1 < decoder_->imageCount; ++frame_index) {
+      avifExtent data_extent;
+      auto rv = avifDecoderNthImageMaxExtent(decoder_.get(), frame_index + 1,
+                                             &data_extent);
+      if (rv != AVIF_RESULT_OK) {
+        DVLOG(1) << "avifDecoderNthImageMaxExtent(" << frame_index + 1
+                 << ") failed: " << avifResultToString(rv) << ": "
+                 << AvifDecoderErrorMessage(decoder_.get());
+        SetFailed();
+        return;
+      }
+      if (data_extent.size != 0 &&
+          data_extent.offset + data_extent.size > data_->size()) {
+        break;
+      }
+    }
+  }
+
+  // Allow AVIF frames to be partially decoded before all data is received.
+  // Only enabled for non-progressive still images because animations look
+  // better without incremental decoding and because progressive decoding makes
+  // incremental decoding unnecessary.
+  decoder_->allowIncremental = (decoder_->imageCount == 1);
+
+  auto ret = DecodeImage(frame_index);
+  if (ret != AVIF_RESULT_OK && ret != AVIF_RESULT_WAITING_ON_IO) {
+    SetFailed();
+    return;
+  }
+  const avifImage* image = decoded_image_;
+
+  // ImageDecoder::SizeCalculationMayOverflow(), called by UpdateDemuxer()
+  // before being here, made sure the image height fits in an int.
+  int displayable_height =
+      static_cast<int>(avifDecoderDecodedRowCount(decoder_.get()));
+  if (image == cropped_image_.get()) {
+    displayable_height -= clap_origin_.y();
+    displayable_height =
+        std::clamp(displayable_height, 0, static_cast<int>(image->height));
+  }
+
+  if (displayable_height == 0) {
+    return;  // There is nothing to display.
+  }
+
+  ImageFrame& buffer = frame_buffer_cache_[index];
+  DCHECK_NE(buffer.GetStatus(), ImageFrame::kFrameComplete);
+
+  if (buffer.GetStatus() == ImageFrame::kFrameEmpty) {
+    if (!InitFrameBuffer(index)) {
+      DVLOG(1) << "Failed to create frame buffer...";
+      SetFailed();
+      return;
+    }
+    DCHECK_EQ(buffer.GetStatus(), ImageFrame::kFramePartial);
+    // The buffer is transparent outside the decoded area while the image is
+    // loading. The correct alpha value for the frame will be set when it is
+    // fully decoded.
+    buffer.SetHasAlpha(true);
+    if (decoder_->allowIncremental) {
+      // In case of buffer disposal after decoding.
+      incrementally_displayed_height_ = 0;
+    }
+  }
+
+  const int last_displayed_height =
+      decoder_->allowIncremental ? incrementally_displayed_height_ : 0;
+  if (displayable_height == last_displayed_height) {
+    return;  // There is no new row to display.
+  }
+  DCHECK_GT(displayable_height, last_displayed_height);
+
+  // Only render the newly decoded rows.
+  if (!RenderImage(image, last_displayed_height, &displayable_height,
+                   &buffer)) {
+    SetFailed();
+    return;
+  }
+  if (displayable_height == last_displayed_height) {
+    return;  // There is no new row to display.
+  }
+  DCHECK_GT(displayable_height, last_displayed_height);
+  ColorCorrectImage(last_displayed_height, displayable_height, &buffer);
+  buffer.SetPixelsChanged(true);
+  if (decoder_->allowIncremental) {
+    incrementally_displayed_height_ = displayable_height;
+  }
+
+  if (static_cast<uint32_t>(displayable_height) == image->height &&
+      (!progressive_ || frame_index + 1 == decoder_->imageCount)) {
+    buffer.SetHasAlpha(!!image->alphaPlane);
+    buffer.SetStatus(ImageFrame::kFrameComplete);
+    PostDecodeProcessing(index);
+  }
+}
+
+bool AVIFImageDecoder::CanReusePreviousFrameBuffer(wtf_size_t index) const {
+  // (a) Technically we can reuse the bitmap of the previous frame because the
+  // AVIF decoder handles frame dependence internally and we never need to
+  // preserve previous frames to decode later ones, and (b) since this function
+  // will not currently be called, this is really more for the reader than any
+  // functional purpose.
+  return true;
+}
+
+// static
+avifResult AVIFImageDecoder::ReadFromSegmentReader(avifIO* io,
+                                                   uint32_t read_flags,
+                                                   uint64_t offset,
+                                                   size_t size,
+                                                   avifROData* out) {
+  if (read_flags != 0) {
+    // Unsupported read_flags
+    return AVIF_RESULT_IO_ERROR;
+  }
+
+  AvifIOData* io_data = static_cast<AvifIOData*>(io->data);
+
+  // Sanitize/clamp incoming request
+  if (offset > io_data->reader->size()) {
+    // The offset is past the end of the buffer or available data.
+    return io_data->all_data_received ? AVIF_RESULT_IO_ERROR
+                                      : AVIF_RESULT_WAITING_ON_IO;
+  }
+
+  // It is more convenient to work with a variable of the size_t type. Since
+  // offset <= io_data->reader->size() <= SIZE_MAX, this cast is safe.
+  size_t position = static_cast<size_t>(offset);
+  const size_t available_size = io_data->reader->size() - position;
+  if (size > available_size) {
+    if (!io_data->all_data_received) {
+      return AVIF_RESULT_WAITING_ON_IO;
+    }
+    size = available_size;
+  }
+
+  out->size = size;
+
+  base::span<const uint8_t> data = io_data->reader->GetSomeData(position);
+  if (data.size() >= size) {
+    out->data = data.data();
+    return AVIF_RESULT_OK;
+  }
+
+  io_data->buffer.clear();
+  io_data->buffer.reserve(size);
+
+  while (size != 0) {
+    data = io_data->reader->GetSomeData(position);
+    size_t copy_size = std::min(data.size(), size);
+    io_data->buffer.insert(io_data->buffer.end(), data.begin(), data.end());
+    position += copy_size;
+    size -= copy_size;
+  }
+
+  out->data = io_data->buffer.data();
+  return AVIF_RESULT_OK;
+}
+
+bool AVIFImageDecoder::UpdateDemuxer() {
+  DCHECK(!Failed());
+  if (IsDecodedSizeAvailable()) {
+    return true;
+  }
+
+  if (have_parsed_current_data_) {
+    return true;
+  }
+  have_parsed_current_data_ = true;
+
+  if (!decoder_) {
+    decoder_.reset(avifDecoderCreate());
+    if (!decoder_) {
+      return false;
+    }
+
+    // For simplicity, use a hardcoded maxThreads of 2, independent of the image
+    // size and processor count. Note: even if we want maxThreads to depend on
+    // the image size, it is impossible to do so because maxThreads is passed to
+    // dav1d_open() inside avifDecoderParse(), but the image size is not known
+    // until avifDecoderParse() returns successfully. See
+    // https://github.com/AOMediaCodec/libavif/issues/636.
+    decoder_->maxThreads = 2;
+
+    if (animation_option_ != AnimationOption::kUnspecified &&
+        avifDecoderSetSource(
+            decoder_.get(),
+            animation_option_ == AnimationOption::kPreferAnimation
+                ? AVIF_DECODER_SOURCE_TRACKS
+                : AVIF_DECODER_SOURCE_PRIMARY_ITEM) != AVIF_RESULT_OK) {
+      return false;
+    }
+
+    // Chrome doesn't use XMP and Exif metadata. Ignoring XMP and Exif will
+    // ensure avifDecoderParse() isn't waiting for some tiny Exif payload hiding
+    // at the end of a file.
+    decoder_->ignoreXMP = AVIF_TRUE;
+    decoder_->ignoreExif = AVIF_TRUE;
+
+    // Turn off libavif's 'clap' (clean aperture) property validation. We
+    // validate 'clap' ourselves and ignore invalid 'clap' properties.
+    decoder_->strictFlags &= ~AVIF_STRICT_CLAP_VALID;
+    // Allow the PixelInformationProperty ('pixi') to be missing in AV1 image
+    // items. libheif v1.11.0 or older does not add the 'pixi' item property to
+    // AV1 image items. (This issue has been corrected in libheif v1.12.0.) See
+    // crbug.com/1198455.
+    decoder_->strictFlags &= ~AVIF_STRICT_PIXI_REQUIRED;
+
+    if (base::FeatureList::IsEnabled(features::kAvifGainmapHdrImages) &&
+        aux_image_ == cc::AuxImage::kGainmap) {
+      decoder_->imageContentToDecode = AVIF_IMAGE_CONTENT_GAIN_MAP;
+    }
+
+    avif_io_.destroy = nullptr;
+    avif_io_.read = ReadFromSegmentReader;
+    avif_io_.write = nullptr;
+    avif_io_.persistent = AVIF_FALSE;
+    avif_io_.data = &avif_io_data_;
+    avifDecoderSetIO(decoder_.get(), &avif_io_);
+  }
+
+  // If all data is received, there is no point in decoding progressively.
+  decoder_->allowProgressive = !IsAllDataReceived();
+
+  auto ret = avifDecoderParse(decoder_.get());
+  if (ret == AVIF_RESULT_WAITING_ON_IO) {
+    return true;
+  }
+  if (ret != AVIF_RESULT_OK) {
+    DVLOG(1) << "avifDecoderParse failed: " << avifResultToString(ret) << ". "
+             << decoder_->diag.error;
+    return false;
+  }
+
+  // Image metadata is available in decoder_->image after avifDecoderParse()
+  // even though decoder_->imageIndex is invalid (-1).
+  DCHECK_EQ(decoder_->imageIndex, -1);
+  // This variable is named |container| to emphasize the fact that the current
+  // contents of decoder_->image come from the container, not any frame.
+  const auto* container = GetDecoderImage();
+  if (!container) {
+    return false;
+  }
+
+  // The container width and container height are read from either the tkhd
+  // (track header) box of a track or the ispe (image spatial extents) property
+  // of an image item, both of which are mandatory in the spec.
+  if (container->width == 0 || container->height == 0) {
+    DVLOG(1) << "Container width and height must be present";
+    return false;
+  }
+
+  // The container depth is read from either the av1C box of a track or the av1C
+  // property of an image item, both of which are mandatory in the spec.
+  if (container->depth == 0) {
+    DVLOG(1) << "Container depth must be present";
+    return false;
+  }
+
+  DCHECK_GT(decoder_->imageCount, 0);
+  progressive_ = decoder_->progressiveState == AVIF_PROGRESSIVE_STATE_ACTIVE;
+  // If the image is progressive, decoder_->imageCount is the number of
+  // progressive frames, but there is only one still image.
+  decoded_frame_count_ = progressive_ ? 1 : decoder_->imageCount;
+  container_width_ = container->width;
+  container_height_ = container->height;
+  bit_depth_ = container->depth;
+  decode_to_half_float_ =
+      ImageIsHighBitDepth() &&
+      high_bit_depth_decoding_option_ == kHighBitDepthToHalfFloat;
+
+  // Verify that AVIF_PIXEL_FORMAT_{YUV444,YUV422,YUV420,YUV400} are
+  // consecutive.
+  static_assert(AVIF_PIXEL_FORMAT_YUV422 == AVIF_PIXEL_FORMAT_YUV444 + 1);
+  static_assert(AVIF_PIXEL_FORMAT_YUV420 == AVIF_PIXEL_FORMAT_YUV422 + 1);
+  static_assert(AVIF_PIXEL_FORMAT_YUV400 == AVIF_PIXEL_FORMAT_YUV420 + 1);
+  // Assert that after avifDecoderParse() returns AVIF_RESULT_OK,
+  // decoder_->image->yuvFormat (the same as container->yuvFormat) is one of the
+  // four YUV formats in AV1.
+  CHECK(container->yuvFormat >= AVIF_PIXEL_FORMAT_YUV444 &&
+        container->yuvFormat <= AVIF_PIXEL_FORMAT_YUV400)
+      << "Invalid YUV format: " << container->yuvFormat;
+  avif_yuv_format_ = container->yuvFormat;
+  avifPixelFormatInfo format_info;
+  avifGetPixelFormatInfo(container->yuvFormat, &format_info);
+  chroma_shift_x_ = format_info.chromaShiftX;
+  chroma_shift_y_ = format_info.chromaShiftY;
+
+  if (container->clli.maxCLL || container->clli.maxPALL) {
+    hdr_metadata_ = gfx::HDRMetadata();
+    hdr_metadata_->cta_861_3 = gfx::HdrMetadataCta861_3(
+        container->clli.maxCLL, container->clli.maxPALL);
+  }
+
+  // SetEmbeddedColorProfile() must be called before IsSizeAvailable() becomes
+  // true. So call SetEmbeddedColorProfile() before calling SetSize(). The color
+  // profile is either an ICC profile or the CICP color description.
+
+  if (!IgnoresColorSpace()) {
+    // The CICP color description is always present because we can always get it
+    // from the AV1 sequence header for the frames. If an ICC profile is
+    // present, use it instead of the CICP color description.
+    if (container->icc.size) {
+      std::unique_ptr<ColorProfile> profile = ColorProfile::Create(
+          base::span(container->icc.data, container->icc.size));
+      if (!profile) {
+        DVLOG(1) << "Failed to parse image ICC profile";
+        return false;
+      }
+      uint32_t data_color_space = profile->GetProfile()->data_color_space;
+      const bool is_mono = container->yuvFormat == AVIF_PIXEL_FORMAT_YUV400;
+      if (is_mono) {
+        if (data_color_space != skcms_Signature_Gray &&
+            data_color_space != skcms_Signature_RGB) {
+          profile = nullptr;
+        }
+      } else {
+        if (data_color_space != skcms_Signature_RGB) {
+          profile = nullptr;
+        }
+      }
+      if (!profile) {
+        DVLOG(1)
+            << "Image contains ICC profile that does not match its color space";
+        return false;
+      }
+      SetEmbeddedColorProfile(std::move(profile));
+    } else if (container->colorPrimaries != AVIF_COLOR_PRIMARIES_UNSPECIFIED ||
+               container->transferCharacteristics !=
+                   AVIF_TRANSFER_CHARACTERISTICS_UNSPECIFIED) {
+      gfx::ColorSpace frame_cs = GetColorSpace(container);
+
+      sk_sp<SkColorSpace> sk_color_space =
+          frame_cs.GetAsFullRangeRGB().ToSkColorSpace();
+      if (!sk_color_space) {
+        DVLOG(1) << "Image contains an unsupported color space";
+        return false;
+      }
+
+      skcms_ICCProfile profile;
+      sk_color_space->toProfile(&profile);
+      SetEmbeddedColorProfile(std::make_unique<ColorProfile>(profile));
+    }
+  }
+
+  // |angle| * 90 specifies the angle of anti-clockwise rotation in degrees.
+  // Legal values: [0-3].
+  int angle = 0;
+  if (container->transformFlags & AVIF_TRANSFORM_IROT) {
+    angle = container->irot.angle;
+    CHECK_LT(angle, 4);
+  }
+  // |axis| specifies how the mirroring is performed.
+  //   -1: No mirroring.
+  //    0: The top and bottom parts of the image are exchanged.
+  //    1: The left and right parts of the image are exchanged.
+  int axis = -1;
+  if (container->transformFlags & AVIF_TRANSFORM_IMIR) {
+    axis = container->imir.axis;
+    CHECK_LT(axis, 2);
+  }
+  // MIAF Section 7.3.6.7 (Clean aperture, rotation and mirror) says:
+  //   These properties, if used, shall be indicated to be applied in the
+  //   following order: clean aperture first, then rotation, then mirror.
+  //
+  // In the kAxisAngleToOrientation array, the first dimension is axis (with an
+  // offset of 1). The second dimension is angle.
+  constexpr std::array<std::array<ImageOrientationEnum, 4>, 3>
+      kAxisAngleToOrientation = {{
+          // No mirroring.
+          {ImageOrientationEnum::kOriginTopLeft,
+           ImageOrientationEnum::kOriginLeftBottom,
+           ImageOrientationEnum::kOriginBottomRight,
+           ImageOrientationEnum::kOriginRightTop},
+          // Top-to-bottom mirroring. Change Top<->Bottom in the first row.
+          {ImageOrientationEnum::kOriginBottomLeft,
+           ImageOrientationEnum::kOriginLeftTop,
+           ImageOrientationEnum::kOriginTopRight,
+           ImageOrientationEnum::kOriginRightBottom},
+          // Left-to-right mirroring. Change Left<->Right in the first row.
+          {ImageOrientationEnum::kOriginTopRight,
+           ImageOrientationEnum::kOriginRightBottom,
+           ImageOrientationEnum::kOriginBottomLeft,
+           ImageOrientationEnum::kOriginLeftTop},
+      }};
+  orientation_ = kAxisAngleToOrientation[axis + 1][angle];
+
+  // Determine whether the image can be decoded to YUV.
+  // * Alpha channel is not supported.
+  // * Multi-frame images (animations) are not supported. (The DecodeToYUV()
+  //   method does not have an 'index' parameter.)
+  allow_decode_to_yuv_ =
+      avif_yuv_format_ != AVIF_PIXEL_FORMAT_YUV400 && !decoder_->alphaPresent &&
+      decoded_frame_count_ == 1 &&
+      GetColorSpace(container).ToSkYUVColorSpace(container->depth,
+                                                 &yuv_color_space_) &&
+      // TODO(crbug.com/911246): Support color space transforms for YUV decodes.
+      !ColorTransform();
+
+  // Record bpp information only for 8-bit, color, still images that do not have
+  // alpha.
+  if (container->depth == 8 && avif_yuv_format_ != AVIF_PIXEL_FORMAT_YUV400 &&
+      !decoder_->alphaPresent && decoded_frame_count_ == 1) {
+    static constexpr char kType[] = "Avif";
+    update_bpp_histogram_callback_ = base::BindOnce(&UpdateBppHistogram<kType>);
+  }
+
+  unsigned width = container->width;
+  unsigned height = container->height;
+  // If the image is cropped, pass the size of the cropped image (the clean
+  // aperture) to SetSize().
+  if (container->transformFlags & AVIF_TRANSFORM_CLAP) {
+    AVIFCleanApertureType clap_type;
+    avifCropRect crop_rect;
+    avifDiagnostics diag;
+    avifBool valid_clap = avifCropRectConvertCleanApertureBox(
+        &crop_rect, &container->clap, container->width, container->height,
+        container->yuvFormat, &diag);
+    if (!valid_clap) {
+      DVLOG(1) << "Invalid 'clap' property: " << diag.error
+               << "; showing the full image.";
+      clap_type = AVIFCleanApertureType::kInvalid;
+      ignore_clap_ = true;
+    } else if (crop_rect.x != 0 || crop_rect.y != 0) {
+      // To help discourage the creation of files with privacy risks, also
+      // consider 'clap' properties whose origins are not at (0, 0) as invalid.
+      // See https://github.com/AOMediaCodec/av1-avif/issues/188 and
+      // https://github.com/AOMediaCodec/av1-avif/issues/189.
+      DVLOG(1) << "Origin of 'clap' property anchored to (" << crop_rect.x
+               << ", " << crop_rect.y << "); showing the full image.";
+      clap_type = AVIFCleanApertureType::kNonzeroOrigin;
+      ignore_clap_ = true;
+    } else {
+      clap_type = AVIFCleanApertureType::kZeroOrigin;
+      clap_origin_.SetPoint(crop_rect.x, crop_rect.y);
+      width = crop_rect.width;
+      height = crop_rect.height;
+    }
+    clap_type_ = clap_type;
+  }
+  return SetSize(width, height);
+}
+
+avifResult AVIFImageDecoder::DecodeImage(wtf_size_t index) {
+  const auto ret = avifDecoderNthImage(decoder_.get(), index);
+  // |index| should be less than what DecodeFrameCount() returns, so we should
+  // not get the AVIF_RESULT_NO_IMAGES_REMAINING error.
+  DCHECK_NE(ret, AVIF_RESULT_NO_IMAGES_REMAINING);
+  if (ret != AVIF_RESULT_OK && ret != AVIF_RESULT_WAITING_ON_IO) {
+    DVLOG(1) << "avifDecoderNthImage(" << index
+             << ") failed: " << avifResultToString(ret) << ": "
+             << AvifDecoderErrorMessage(decoder_.get());
+    return ret;
+  }
+
+  const auto* image = GetDecoderImage();
+  CHECK(image);
+  // Frame size must be equal to container size.
+  if (image->width != container_width_ || image->height != container_height_) {
+    DVLOG(1) << "Frame size " << image->width << "x" << image->height
+             << " differs from container size " << container_width_ << "x"
+             << container_height_;
+    return AVIF_RESULT_UNKNOWN_ERROR;
+  }
+  // Frame bit depth must be equal to container bit depth.
+  if (image->depth != bit_depth_) {
+    DVLOG(1) << "Frame bit depth must be equal to container bit depth";
+    return AVIF_RESULT_UNKNOWN_ERROR;
+  }
+  // Frame YUV format must be equal to container YUV format.
+  if (image->yuvFormat != avif_yuv_format_) {
+    DVLOG(1) << "Frame YUV format must be equal to container YUV format";
+    return AVIF_RESULT_UNKNOWN_ERROR;
+  }
+
+  decoded_image_ = image;
+  if ((image->transformFlags & AVIF_TRANSFORM_CLAP) && !ignore_clap_) {
+    CropDecodedImage();
+  }
+
+  if (ret == AVIF_RESULT_OK) {
+    if (IsAllDataReceived() && update_bpp_histogram_callback_) {
+      std::move(update_bpp_histogram_callback_).Run(Size(), data_->size());
+    }
+
+    if (clap_type_.has_value()) {
+      base::UmaHistogramEnumeration("Blink.ImageDecoders.Avif.CleanAperture",
+                                    clap_type_.value());
+      clap_type_.reset();
+    }
+  }
+  return ret;
+}
+
+void AVIFImageDecoder::CropDecodedImage() {
+  DCHECK_NE(decoded_image_, cropped_image_.get());
+  if (!cropped_image_) {
+    cropped_image_.reset(avifImageCreateEmpty());
+  }
+  avifCropRect rect;
+  rect.x = clap_origin_.x();
+  rect.y = clap_origin_.y();
+  rect.width = Size().width();
+  rect.height = Size().height();
+  const avifResult result =
+      avifImageSetViewRect(cropped_image_.get(), decoded_image_, &rect);
+  CHECK_EQ(result, AVIF_RESULT_OK);
+  decoded_image_ = cropped_image_.get();
+}
+
+bool AVIFImageDecoder::RenderImage(const avifImage* image,
+                                   int from_row,
+                                   int* to_row,
+                                   ImageFrame* buffer) {
+  DCHECK_LT(from_row, *to_row);
+
+  // libavif uses libyuv for the YUV 4:2:0 to RGB upsampling and/or conversion
+  // as follows:
+  //  - convert the top RGB row 0,
+  //  - convert the RGB rows 1 and 2, then RGB rows 3 and 4 etc.,
+  //  - convert the bottom (odd) RGB row if there is an even number of RGB rows.
+  //
+  // Unfortunately this cannot be applied incrementally as is. The RGB values
+  // would differ because the first and last RGB rows have a formula using only
+  // one UV row, while the other RGB rows use two UV rows as input each.
+  // See https://crbug.com/libyuv/934.
+  //
+  // The workaround is a backup of the last converted even RGB row, called top
+  // row, located right before |from_row|. The conversion is then called
+  // starting at this top row, overwriting it with invalid values. The remaining
+  // pairs of rows are correctly aligned and their freshly converted values are
+  // valid. Then the backed up row is put back, fixing the issue.
+  // The bottom row is postponed if the other half of the pair it belongs to is
+  // not yet decoded.
+  //
+  //  UV rows |                 Y/RGB rows
+  //          |  all  |  first decoding  |  second decoding
+  //           ____ 0  ____ 0 (from_row)
+  //    0 ---- ____ 1  ____ 1
+  //           ____ 2  ____ 2             ____ 2 (backed up)
+  //    1 ---- ____ 3  ____ 3 (postponed) ____ 3 (from_row)
+  //           ____ 4       4 (*to_row)   ____ 4
+  //    2 ---- ____ 5                     ____ 5
+  //                                           6 (*to_row)
+
+  const bool use_libyuv_bilinear_upsampling =
+      !decode_to_half_float_ && image->yuvFormat == AVIF_PIXEL_FORMAT_YUV420;
+  const bool save_top_row = use_libyuv_bilinear_upsampling && from_row > 0;
+  const bool postpone_bottom_row =
+      use_libyuv_bilinear_upsampling &&
+      static_cast<uint32_t>(*to_row) < image->height;
+  if (postpone_bottom_row) {
+    // libavif outputs an even number of rows because 4:2:0 samples are decoded
+    // in pairs.
+    DCHECK(!(*to_row & 1));
+    --*to_row;
+    if (from_row == *to_row) {
+      return true;  // Nothing to do.
+    }
+  }
+  if (save_top_row) {
+    // |from_row| is odd because it is equal to the output value of |*to_row|
+    // from the previous RenderImage() call, and |*to_row| was even and then
+    // decremented at that time.
+    DCHECK(from_row & 1);
+    --from_row;
+  }
+
+  // Focus |image| on rows [from_row, *to_row).
+  std::unique_ptr<avifImage, decltype(&avifImageDestroy)> view(
+      nullptr, avifImageDestroy);
+  if (from_row > 0 || static_cast<uint32_t>(*to_row) < image->height) {
+    const avifCropRect rect = {0, static_cast<uint32_t>(from_row), image->width,
+                               static_cast<uint32_t>(*to_row - from_row)};
+    view.reset(avifImageCreateEmpty());
+    const avifResult result = avifImageSetViewRect(view.get(), image, &rect);
+    CHECK_EQ(result, AVIF_RESULT_OK);
+    image = view.get();
+  }
+
+  avifRGBImage rgb_image;
+  avifRGBImageSetDefaults(&rgb_image, image);
+
+  if (decode_to_half_float_) {
+    rgb_image.depth = 16;
+    rgb_image.isFloat = AVIF_TRUE;
+    rgb_image.pixels =
+        reinterpret_cast<uint8_t*>(buffer->GetAddrF16(0, from_row));
+    rgb_image.rowBytes = image->width * sizeof(uint64_t);
+    // When decoding to half float, the pixel ordering is always RGBA on all
+    // platforms.
+    rgb_image.format = AVIF_RGB_FORMAT_RGBA;
+  } else {
+    rgb_image.depth = 8;
+    rgb_image.pixels = reinterpret_cast<uint8_t*>(buffer->GetAddr(0, from_row));
+    rgb_image.rowBytes = image->width * sizeof(uint32_t);
+    // When decoding to 8-bit, Android uses little-endian RGBA pixels. All other
+    // platforms use BGRA pixels.
+    static_assert(SK_B32_SHIFT == 16 - SK_R32_SHIFT);
+    static_assert(SK_G32_SHIFT == 8);
+    static_assert(SK_A32_SHIFT == 24);
+#if SK_B32_SHIFT
+    rgb_image.format = AVIF_RGB_FORMAT_RGBA;
+#else
+    rgb_image.format = AVIF_RGB_FORMAT_BGRA;
+#endif
+  }
+  rgb_image.alphaPremultiplied = buffer->PremultiplyAlpha();
+  rgb_image.maxThreads = decoder_->maxThreads;
+
+  if (save_top_row) {
+    previous_last_decoded_row_.resize(rgb_image.rowBytes);
+    memcpy(previous_last_decoded_row_.data(), rgb_image.pixels,
+           rgb_image.rowBytes);
+  }
+  const avifResult result = avifImageYUVToRGB(image, &rgb_image);
+  if (save_top_row) {
+    memcpy(rgb_image.pixels, previous_last_decoded_row_.data(),
+           rgb_image.rowBytes);
+  }
+  return result == AVIF_RESULT_OK;
+}
+
+void AVIFImageDecoder::ColorCorrectImage(int from_row,
+                                         int to_row,
+                                         ImageFrame* buffer) {
+  // Postprocess the image data according to the profile.
+  const ColorProfileTransform* const transform = ColorTransform();
+  if (!transform) {
+    return;
+  }
+  const auto alpha_format = (buffer->HasAlpha() && buffer->PremultiplyAlpha())
+                                ? skcms_AlphaFormat_PremulAsEncoded
+                                : skcms_AlphaFormat_Unpremul;
+  if (decode_to_half_float_) {
+    const skcms_PixelFormat color_format = skcms_PixelFormat_RGBA_hhhh;
+    for (int y = from_row; y < to_row; ++y) {
+      ImageFrame::PixelDataF16* const row = buffer->GetAddrF16(0, y);
+      const bool success = skcms_Transform(
+          row, color_format, alpha_format, transform->SrcProfile(), row,
+          color_format, alpha_format, transform->DstProfile(), Size().width());
+      DCHECK(success);
+    }
+  } else {
+    const skcms_PixelFormat color_format = XformColorFormat();
+    for (int y = from_row; y < to_row; ++y) {
+      ImageFrame::PixelData* const row = buffer->GetAddr(0, y);
+      const bool success = skcms_Transform(
+          row, color_format, alpha_format, transform->SrcProfile(), row,
+          color_format, alpha_format, transform->DstProfile(), Size().width());
+      DCHECK(success);
+    }
+  }
+}
+
+bool AVIFImageDecoder::GetGainmapInfoAndData(
+    SkGainmapInfo& out_gainmap_info,
+    scoped_refptr<SegmentReader>& out_gainmap_data) const {
+  if (!base::FeatureList::IsEnabled(features::kAvifGainmapHdrImages)) {
+    return false;
+  }
+  // Ensure that parsing succeeded.
+  if (!IsDecodedSizeAvailable()) {
+    return false;
+  }
+  if (!decoder_->image->gainMap) {
+    return false;
+  }
+  const avifGainMap& gain_map = *decoder_->image->gainMap;
+  if (gain_map.baseHdrHeadroom.d == 0 || gain_map.alternateHdrHeadroom.d == 0) {
+    DVLOG(1) << "Invalid gainmap metadata: a denominator value is zero";
+    return false;
+  }
+  const float base_headroom = std::exp2(
+      FractionToFloat(gain_map.baseHdrHeadroom.n, gain_map.baseHdrHeadroom.d));
+  const float alternate_headroom = std::exp2(FractionToFloat(
+      gain_map.alternateHdrHeadroom.n, gain_map.alternateHdrHeadroom.d));
+  const bool base_is_hdr = base_headroom > alternate_headroom;
+  out_gainmap_info.fDisplayRatioSdr =
+      base_is_hdr ? alternate_headroom : base_headroom;
+  out_gainmap_info.fDisplayRatioHdr =
+      base_is_hdr ? base_headroom : alternate_headroom;
+  out_gainmap_info.fBaseImageType = base_is_hdr
+                                        ? SkGainmapInfo::BaseImageType::kHDR
+                                        : SkGainmapInfo::BaseImageType::kSDR;
+  if (!gain_map.useBaseColorSpace) {
+    // Try to use the alternate image's color space.
+    out_gainmap_info.fGainmapMathColorSpace =
+        GetAltImageColorSpace(*decoder_->image);
+  }
+  for (int i = 0; i < 3; ++i) {
+    if (gain_map.gainMapMin[i].d == 0 || gain_map.gainMapMax[i].d == 0 ||
+        gain_map.gainMapGamma[i].d == 0 || gain_map.baseOffset[i].d == 0 ||
+        gain_map.alternateOffset[i].d == 0) {
+      DVLOG(1) << "Invalid gainmap metadata: a denominator value is zero";
+      return false;
+    }
+    if (gain_map.gainMapGamma[i].n == 0) {
+      DVLOG(1) << "Invalid gainmap metadata: gamma is zero";
+      return false;
+    }
+
+    const float min_log2 =
+        FractionToFloat(gain_map.gainMapMin[i].n, gain_map.gainMapMin[i].d);
+    const float max_log2 =
+        FractionToFloat(gain_map.gainMapMax[i].n, gain_map.gainMapMax[i].d);
+    out_gainmap_info.fGainmapRatioMin[i] = std::exp2(min_log2);
+    out_gainmap_info.fGainmapRatioMax[i] = std::exp2(max_log2);
+
+    // Numerator and denominator intentionally swapped to get 1.0/gamma.
+    out_gainmap_info.fGainmapGamma[i] =
+        FractionToFloat(gain_map.gainMapGamma[i].d, gain_map.gainMapGamma[i].n);
+    const float base_offset =
+        FractionToFloat(gain_map.baseOffset[i].n, gain_map.baseOffset[i].d);
+    const float alternate_offset = FractionToFloat(
+        gain_map.alternateOffset[i].n, gain_map.alternateOffset[i].d);
+    out_gainmap_info.fEpsilonSdr[i] =
+        base_is_hdr ? alternate_offset : base_offset;
+    out_gainmap_info.fEpsilonHdr[i] =
+        base_is_hdr ? base_offset : alternate_offset;
+  }
+  out_gainmap_data = data_;
+  return true;
+}
+
+avifImage* AVIFImageDecoder::GetDecoderImage() const {
+  if (aux_image_ == cc::AuxImage::kGainmap) {
+    if (!decoder_->image->gainMap) {
+      DVLOG(1) << "Attempted to access gain map image, but gainMap is nullptr";
+      return nullptr;
+    }
+    return decoder_->image->gainMap->image;
+  }
+  return decoder_->image;
+}
+
+AVIFImageDecoder::AvifIOData::AvifIOData() = default;
+AVIFImageDecoder::AvifIOData::AvifIOData(
+    scoped_refptr<const SegmentReader> reader,
+    bool all_data_received)
+    : reader(std::move(reader)), all_data_received(all_data_received) {}
+AVIFImageDecoder::AvifIOData::~AvifIOData() = default;
+
+}  // namespace blink
diff --git a/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h
new file mode 100644
index 0000000000000..75247663ef158
--- /dev/null
+++ b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h
@@ -0,0 +1,191 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef THIRD_PARTY_BLINK_RENDERER_PLATFORM_IMAGE_DECODERS_AVIF_AVIF_IMAGE_DECODER_H_
+#define THIRD_PARTY_BLINK_RENDERER_PLATFORM_IMAGE_DECODERS_AVIF_AVIF_IMAGE_DECODER_H_
+
+#include <memory>
+#include <vector>
+
+#include "base/functional/callback.h"
+#include "third_party/blink/renderer/platform/allow_discouraged_type.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_decoder.h"
+#include "third_party/blink/renderer/platform/wtf/vector.h"
+#include "third_party/libavif/src/include/avif/avif.h"
+#include "third_party/skia/include/core/SkImageInfo.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/geometry/point.h"
+
+namespace blink {
+
+class FastSharedBufferReader;
+
+class PLATFORM_EXPORT AVIFImageDecoder final : public ImageDecoder {
+ public:
+  AVIFImageDecoder(AlphaOption,
+                   HighBitDepthDecodingOption,
+                   ColorBehavior,
+                   cc::AuxImage,
+                   wtf_size_t max_decoded_bytes,
+                   AnimationOption);
+  AVIFImageDecoder(const AVIFImageDecoder&) = delete;
+  AVIFImageDecoder& operator=(const AVIFImageDecoder&) = delete;
+  ~AVIFImageDecoder() override;
+
+  // ImageDecoder:
+  String FilenameExtension() const override;
+  const AtomicString& MimeType() const override;
+  bool ImageIsHighBitDepth() override;
+  void OnSetData(scoped_refptr<SegmentReader> data) override;
+  bool GetGainmapInfoAndData(
+      SkGainmapInfo& out_gainmap_info,
+      scoped_refptr<SegmentReader>& out_gainmap_data) const override;
+  cc::YUVSubsampling GetYUVSubsampling() const override;
+  gfx::Size DecodedYUVSize(cc::YUVIndex) const override;
+  wtf_size_t DecodedYUVWidthBytes(cc::YUVIndex) const override;
+  SkYUVColorSpace GetYUVColorSpace() const override;
+  uint8_t GetYUVBitDepth() const override;
+  std::optional<gfx::HDRMetadata> GetHDRMetadata() const override;
+  void DecodeToYUV() override;
+  int RepetitionCount() const override;
+  bool FrameIsReceivedAtIndex(wtf_size_t) const override;
+  std::optional<base::TimeDelta> FrameTimestampAtIndex(
+      wtf_size_t) const override;
+  base::TimeDelta FrameDurationAtIndex(wtf_size_t) const override;
+  bool ImageHasBothStillAndAnimatedSubImages() const override;
+
+  // Returns true if the data in fast_reader begins with a valid FileTypeBox
+  // (ftyp) that supports the brand 'avif' or 'avis'.
+  static bool MatchesAVIFSignature(const FastSharedBufferReader& fast_reader);
+
+  gfx::ColorSpace GetColorSpaceForTesting() const;
+
+ private:
+  // If the AVIF image has a clean aperture ('clap') property, what kind of
+  // clean aperture it is. Values synced with 'AVIFCleanApertureType' in
+  // src/tools/metrics/histograms/enums.xml.
+  //
+  // These values are persisted to logs. Entries should not be renumbered and
+  // numeric values should never be reused.
+  enum class AVIFCleanApertureType {
+    kInvalid = 0,        // The clean aperture property is invalid.
+    kNonzeroOrigin = 1,  // The origin of the clean aperture is not (0, 0).
+    kZeroOrigin = 2,     // The origin of the clean aperture is (0, 0).
+    kMaxValue = kZeroOrigin,
+  };
+
+  struct AvifIOData {
+    AvifIOData();
+    AvifIOData(scoped_refptr<const SegmentReader> reader,
+               bool all_data_received);
+    ~AvifIOData();
+
+    scoped_refptr<const SegmentReader> reader;
+    std::vector<uint8_t> buffer ALLOW_DISCOURAGED_TYPE("Required by libavif");
+    bool all_data_received = false;
+  };
+
+  void ParseMetadata();
+
+  // ImageDecoder:
+  void DecodeSize() override;
+  wtf_size_t DecodeFrameCount() override;
+  void InitializeNewFrame(wtf_size_t) override;
+  void Decode(wtf_size_t) override;
+  bool CanReusePreviousFrameBuffer(wtf_size_t) const override;
+
+  // Implements avifIOReadFunc, the |read| function in the avifIO struct.
+  static avifResult ReadFromSegmentReader(avifIO* io,
+                                          uint32_t read_flags,
+                                          uint64_t offset,
+                                          size_t size,
+                                          avifROData* out);
+
+  // Creates |decoder_| if not yet created and decodes the size and frame count.
+  bool UpdateDemuxer();
+
+  // Decodes the frame at index |index| and checks if the frame's size, bit
+  // depth, and YUV format matches those reported by the container. The decoded
+  // frame is available in decoded_image_.
+  avifResult DecodeImage(wtf_size_t index);
+
+  // Crops |decoded_image_|.
+  void CropDecodedImage();
+
+  // Renders the rows [from_row, *to_row) of |image| to |buffer|. Returns
+  // whether |image| was rendered successfully. On return, the in/out argument
+  // |*to_row| may be decremented in case of subsampled chroma needing more
+  // data.
+  bool RenderImage(const avifImage* image,
+                   int from_row,
+                   int* to_row,
+                   ImageFrame* buffer);
+
+  // Applies color profile correction to the rows [from_row, to_row) of
+  // |buffer|, if desired.
+  void ColorCorrectImage(int from_row, int to_row, ImageFrame* buffer);
+
+  // Returns decoder_->image or decoder_->image->gainMap->image depending on
+  // aux_image_. May be nullptr if requesting the gain map image
+  // (cc::AuxImage::kGainmap) but no gain map is present.
+  avifImage* GetDecoderImage() const;
+
+  bool have_parsed_current_data_ = false;
+  // The image width and height (before cropping, if any) from the container.
+  //
+  // Note: container_width_, container_height_, decoder_->image->width, and
+  // decoder_->image->height are the width and height of the full image. Size()
+  // returns the size of the cropped image (the clean aperture).
+  uint32_t container_width_ = 0;
+  uint32_t container_height_ = 0;
+  // The bit depth from the container.
+  uint8_t bit_depth_ = 0;
+  bool decode_to_half_float_ = false;
+  uint8_t chroma_shift_x_ = 0;
+  uint8_t chroma_shift_y_ = 0;
+  std::optional<gfx::HDRMetadata> hdr_metadata_;
+  bool progressive_ = false;
+  // Number of displayed rows for a non-progressive still image.
+  int incrementally_displayed_height_ = 0;
+  // The YUV format from the container.
+  avifPixelFormat avif_yuv_format_ = AVIF_PIXEL_FORMAT_NONE;
+  wtf_size_t decoded_frame_count_ = 0;
+  SkYUVColorSpace yuv_color_space_ = SkYUVColorSpace::kIdentity_SkYUVColorSpace;
+  // Used to call UpdateBppHistogram<"Avif">() at most once to record the
+  // bits-per-pixel value of the image when the image is successfully decoded.
+  base::OnceCallback<void(gfx::Size, size_t)> update_bpp_histogram_callback_;
+  std::optional<AVIFCleanApertureType> clap_type_;
+  // Whether the 'clap' (clean aperture) property should be ignored, e.g.
+  // because the 'clap' property is invalid or unsupported.
+  bool ignore_clap_ = false;
+  // The origin (top left corner) of the clean aperture. Used only when the
+  // image has a valid 'clap' (clean aperture) property.
+  gfx::Point clap_origin_;
+  // A copy of decoder_->image with the width, height, and plane buffers
+  // adjusted to those of the clean aperture. Used only when the image has a
+  // 'clap' (clean aperture) property.
+  std::unique_ptr<avifImage, decltype(&avifImageDestroy)> cropped_image_{
+      nullptr, avifImageDestroy};
+  // Set by a successful DecodeImage() call to either decoder_->image or
+  // cropped_image_.get() depending on whether the image has a 'clap' (clean
+  // aperture) property.
+  raw_ptr<const avifImage, DanglingUntriaged> decoded_image_ = nullptr;
+  // The declaration order of the next three fields is important. decoder_
+  // points to avif_io_, and avif_io_ points to avif_io_data_. The destructor
+  // must destroy them in that order.
+  AvifIOData avif_io_data_;
+  avifIO avif_io_ = {};
+  std::unique_ptr<avifDecoder, decltype(&avifDecoderDestroy)> decoder_{
+      nullptr, avifDecoderDestroy};
+
+  const AnimationOption animation_option_;
+
+  // Used temporarily for incremental decoding and for some YUV to RGB color
+  // conversions.
+  Vector<uint8_t> previous_last_decoded_row_;
+};
+
+}  // namespace blink
+
+#endif  // THIRD_PARTY_BLINK_RENDERER_PLATFORM_IMAGE_DECODERS_AVIF_AVIF_IMAGE_DECODER_H_
diff --git a/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_fuzzer.cc b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_fuzzer.cc
new file mode 100644
index 0000000000000..f337ad075244a
--- /dev/null
+++ b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_fuzzer.cc
@@ -0,0 +1,30 @@
+// Copyright 2024 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#include "third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h"
+
+#include <fuzzer/FuzzedDataProvider.h>
+#include <stddef.h>
+#include <stdint.h>
+
+#include <memory>
+
+#include "third_party/blink/renderer/platform/graphics/color_behavior.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_decoder.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h"
+#include "third_party/blink/renderer/platform/testing/blink_fuzzer_test_support.h"
+#include "third_party/blink/renderer/platform/testing/task_environment.h"
+#include "third_party/blink/renderer/platform/wtf/shared_buffer.h"
+#include "third_party/blink/renderer/platform/wtf/wtf_size_t.h"
+
+namespace blink {
+
+extern "C" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {
+  static BlinkFuzzerTestSupport test_support;
+  FuzzedDataProvider fdp(data, size);
+  FuzzDecoder(DecoderType::kAvifDecoder, fdp);
+  return 0;
+}
+
+}  // namespace blink
diff --git a/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_test.cc b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_test.cc
new file mode 100644
index 0000000000000..9ec2b420bdf7d
--- /dev/null
+++ b/third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder_test.cc
@@ -0,0 +1,1758 @@
+// Copyright 2020 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifdef UNSAFE_BUFFERS_BUILD
+// TODO(crbug.com/351564777): Remove this and convert code to safer constructs.
+#pragma allow_unsafe_buffers
+#endif
+
+#include "third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h"
+
+#include <cmath>
+#include <memory>
+#include <ostream>
+#include <utility>
+#include <vector>
+
+#include "base/barrier_closure.h"
+#include "base/bit_cast.h"
+#include "base/functional/bind.h"
+#include "base/strings/stringprintf.h"
+#include "base/synchronization/waitable_event.h"
+#include "base/task/thread_pool.h"
+#include "base/test/metrics/histogram_tester.h"
+#include "base/test/scoped_feature_list.h"
+#include "base/test/task_environment.h"
+#include "testing/gtest/include/gtest/gtest.h"
+#include "third_party/blink/public/common/features.h"
+#include "third_party/blink/public/platform/platform.h"
+#include "third_party/blink/renderer/platform/image-decoders/image_decoder_test_helpers.h"
+#include "third_party/blink/renderer/platform/wtf/shared_buffer.h"
+#include "ui/gfx/color_space.h"
+#include "ui/gfx/color_transform.h"
+
+#define FIXME_SUPPORT_ICC_PROFILE_NO_TRANSFORM 0
+#define FIXME_SUPPORT_ICC_PROFILE_TRANSFORM 0
+#define FIXME_DISTINGUISH_LOSSY_OR_LOSSLESS 0
+
+namespace blink {
+
+namespace {
+
+std::unique_ptr<ImageDecoder> CreateAVIFDecoderWithOptions(
+    ImageDecoder::AlphaOption alpha_option,
+    ImageDecoder::HighBitDepthDecodingOption high_bit_depth_option,
+    ColorBehavior color_behavior,
+    cc::AuxImage aux_image,
+    ImageDecoder::AnimationOption animation_option) {
+  return std::make_unique<AVIFImageDecoder>(
+      alpha_option, high_bit_depth_option, color_behavior, aux_image,
+      ImageDecoder::kNoDecodedImageByteLimit, animation_option);
+}
+
+std::unique_ptr<ImageDecoder> CreateAVIFDecoder() {
+  return CreateAVIFDecoderWithOptions(
+      ImageDecoder::kAlphaNotPremultiplied, ImageDecoder::kDefaultBitDepth,
+      ColorBehavior::kTag, cc::AuxImage::kDefault,
+      ImageDecoder::AnimationOption::kUnspecified);
+}
+
+std::unique_ptr<ImageDecoder> CreateGainMapAVIFDecoder() {
+  return CreateAVIFDecoderWithOptions(
+      ImageDecoder::kAlphaNotPremultiplied, ImageDecoder::kDefaultBitDepth,
+      ColorBehavior::kTag, cc::AuxImage::kGainmap,
+      ImageDecoder::AnimationOption::kUnspecified);
+}
+
+struct ExpectedColor {
+  gfx::Point point;
+  SkColor color;
+};
+
+enum class ColorType {
+  kRgb,
+  kRgbA,
+  kMono,
+  kMonoA,
+};
+
+struct StaticColorCheckParam {
+  const char* path;
+  int bit_depth;
+  ColorType color_type;
+  ImageDecoder::CompressionFormat compression_format;
+  ImageDecoder::AlphaOption alpha_option;
+  ColorBehavior color_behavior;
+  ImageOrientationEnum orientation = ImageOrientationEnum::kDefault;
+  int color_threshold;
+  std::vector<ExpectedColor> colors;
+};
+
+std::ostream& operator<<(std::ostream& os, const StaticColorCheckParam& param) {
+  const char* color_type;
+  switch (param.color_type) {
+    case ColorType::kRgb:
+      color_type = "kRgb";
+      break;
+    case ColorType::kRgbA:
+      color_type = "kRgbA";
+      break;
+    case ColorType::kMono:
+      color_type = "kMono";
+      break;
+    case ColorType::kMonoA:
+      color_type = "kMonoA";
+      break;
+  }
+  const char* alpha_option =
+      (param.alpha_option == ImageDecoder::kAlphaPremultiplied
+           ? "kAlphaPremultiplied"
+           : "kAlphaNotPremultiplied");
+  const char* color_behavior;
+  if (param.color_behavior == ColorBehavior::kIgnore) {
+    color_behavior = "Ignore";
+  } else if (param.color_behavior == ColorBehavior::kTag) {
+    color_behavior = "Tag";
+  } else {
+    DCHECK(param.color_behavior == ColorBehavior::kTransformToSRGB);
+    color_behavior = "TransformToSRGB";
+  }
+  const char* orientation;
+  switch (param.orientation) {
+    case ImageOrientationEnum::kOriginTopLeft:
+      orientation = "kOriginTopLeft";
+      break;
+    case ImageOrientationEnum::kOriginTopRight:
+      orientation = "kOriginTopRight";
+      break;
+    case ImageOrientationEnum::kOriginBottomRight:
+      orientation = "kOriginBottomRight";
+      break;
+    case ImageOrientationEnum::kOriginBottomLeft:
+      orientation = "kOriginBottomLeft";
+      break;
+    case ImageOrientationEnum::kOriginLeftTop:
+      orientation = "kOriginLeftTop";
+      break;
+    case ImageOrientationEnum::kOriginRightTop:
+      orientation = "kOriginRightTop";
+      break;
+    case ImageOrientationEnum::kOriginRightBottom:
+      orientation = "kOriginRightBottom";
+      break;
+    case ImageOrientationEnum::kOriginLeftBottom:
+      orientation = "kOriginLeftBottom";
+      break;
+  }
+  return os << "\nStaticColorCheckParam {\n  path: \"" << param.path
+            << "\",\n  bit_depth: " << param.bit_depth
+            << ",\n  color_type: " << color_type
+            << ",\n  alpha_option: " << alpha_option
+            << ",\n  color_behavior: " << color_behavior
+            << ",\n  orientation: " << orientation << "\n}";
+}
+
+StaticColorCheckParam kTestParams[] = {
+    {
+        "/images/resources/avif/red-at-12-oclock-with-color-profile-lossy.avif",
+        8,
+        ColorType::kRgb,
+        ImageDecoder::kLossyFormat,
+        ImageDecoder::kAlphaNotPremultiplied,  // q=60(lossy)
+        ColorBehavior::kTag,
+        ImageOrientationEnum::kOriginTopLeft,
+        0,
+        {},  // we just check that this image is lossy.
+    },
+    {
+        "/images/resources/avif/red-at-12-oclock-with-color-profile-lossy.avif",
+        8,
+        ColorType::kRgb,
+        ImageDecoder::kLossyFormat,
+        ImageDecoder::kAlphaNotPremultiplied,  // q=60(lossy)
+        ColorBehavior::kIgnore,
+        ImageOrientationEnum::kOriginTopLeft,
+        0,
+        {},  // we just check that the decoder won't crash when
+             // ColorBehavior::kIgnore is used.
+    },
+    {"/images/resources/avif/red-with-alpha-8bpc.avif",
+     8,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     3,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(127, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-unspecified-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/silver-full-range-srgb-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 192, 192, 192)},
+     }},
+    {"/images/resources/avif/silver-400-matrix-6.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 192, 192, 192)},
+     }},
+    {"/images/resources/avif/silver-400-matrix-0.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 192, 192, 192)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 192, 192, 192)},
+     }},
+    {"/images/resources/avif/alpha-mask-limited-range-8bpc.avif",
+     8,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+    {"/images/resources/avif/alpha-mask-full-range-8bpc.avif",
+     8,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+    {"/images/resources/avif/red-with-alpha-8bpc.avif",
+     8,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     4,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(127, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+#if FIXME_SUPPORT_ICC_PROFILE_NO_TRANSFORM
+    {"/images/resources/avif/red-with-profile-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kIgnore,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 0, 0, 255)},
+     }},
+#endif
+#if FIXME_SUPPORT_ICC_PROFILE_TRANSFORM
+    {"/images/resources/avif/red-with-profile-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         /*
+          * "Color Spin" ICC profile, embedded in this image,
+          * changes blue to red.
+          */
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+#endif
+    {"/images/resources/avif/red-with-alpha-10bpc.avif",
+     10,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     2,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(128, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-with-alpha-10bpc.avif",
+     10,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     2,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(128, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-420-10bpc.avif",
+     10,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/alpha-mask-limited-range-10bpc.avif",
+     10,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+    {"/images/resources/avif/alpha-mask-full-range-10bpc.avif",
+     10,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+#if FIXME_SUPPORT_ICC_PROFILE_NO_TRANSFORM
+    {"/images/resources/avif/red-with-profile-10bpc.avif",
+     10,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kIgnore,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 0, 0, 255)},
+     }},
+#endif
+#if FIXME_SUPPORT_ICC_PROFILE_TRANSFORM
+    {"/images/resources/avif/red-with-profile-10bpc.avif",
+     10,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         /*
+          * "Color Spin" ICC profile, embedded in this image,
+          * changes blue to red.
+          */
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+#endif
+    {"/images/resources/avif/red-with-alpha-12bpc.avif",
+     12,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     2,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(128, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-with-alpha-12bpc.avif",
+     12,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     2,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(0, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(128, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-420-12bpc.avif",
+     12,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/alpha-mask-limited-range-12bpc.avif",
+     12,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+    {"/images/resources/avif/alpha-mask-full-range-12bpc.avif",
+     12,
+     ColorType::kMono,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 128, 128, 128)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 255, 255)},
+     }},
+#if FIXME_SUPPORT_ICC_PROFILE_NO_TRANSFORM
+    {"/images/resources/avif/red-with-profile-12bpc.avif",
+     12,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kIgnore,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 0, 0, 255)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 0, 0, 255)},
+     }},
+#endif
+#if FIXME_SUPPORT_ICC_PROFILE_TRANSFORM
+    {"/images/resources/avif/red-with-profile-12bpc.avif",
+     12,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTransformToSRGB,
+     ImageOrientationEnum::kOriginTopLeft,
+     1,
+     {
+         /*
+          * "Color Spin" ICC profile, embedded in this image,
+          * changes blue to red.
+          */
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+#endif
+    {"/images/resources/avif/red-and-purple-crop.avif",
+     8,
+     ColorType::kRgbA,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopLeft,
+     0,
+     {
+         // The clean aperture's size is 200x50. The left half is red and the
+         // right half is purple. Alpha values in the clean aperture are 255.
+         // (Alpha values to the right of the clean aperture are 128.)
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},       // red
+         {gfx::Point(99, 24), SkColorSetARGB(255, 255, 0, 0)},     // red
+         {gfx::Point(100, 25), SkColorSetARGB(255, 127, 0, 128)},  // purple
+         {gfx::Point(199, 49), SkColorSetARGB(255, 127, 0, 128)},  // purple
+     }},
+    {"/images/resources/avif/red-full-range-angle-1-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginLeftBottom,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-mode-0-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginBottomLeft,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-mode-1-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopRight,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-angle-2-mode-0-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginTopRight,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    {"/images/resources/avif/red-full-range-angle-3-mode-1-420-8bpc.avif",
+     8,
+     ColorType::kRgb,
+     ImageDecoder::kLosslessFormat,
+     ImageDecoder::kAlphaNotPremultiplied,
+     ColorBehavior::kTag,
+     ImageOrientationEnum::kOriginLeftTop,
+     0,
+     {
+         {gfx::Point(0, 0), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(1, 1), SkColorSetARGB(255, 255, 0, 0)},
+         {gfx::Point(2, 2), SkColorSetARGB(255, 255, 0, 0)},
+     }},
+    // TODO(ryoh): Add other color profile images, such as BT2020CL,
+    //  SMPTE 274M
+    // TODO(ryoh): Add images with different combinations of ColorPrimaries,
+    //  TransferFunction and MatrixCoefficients,
+    //  such as:
+    //   sRGB ColorPrimaries, BT.2020 TransferFunction and
+    //   BT.709 MatrixCoefficients
+    // TODO(ryoh): Add Mono + Alpha Images.
+};
+
+enum class ErrorPhase { kParse, kDecode };
+
+// If 'error_phase' is ErrorPhase::kParse, error is expected during parse
+// (SetData() call); else error is expected during decode
+// (DecodeFrameBufferAtIndex() call).
+void TestInvalidStaticImage(const char* avif_file, ErrorPhase error_phase) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(avif_file);
+  ASSERT_TRUE(data.get());
+  decoder->SetData(std::move(data), true);
+
+  if (error_phase == ErrorPhase::kParse) {
+    EXPECT_FALSE(decoder->IsSizeAvailable());
+    EXPECT_TRUE(decoder->Failed());
+    EXPECT_EQ(0u, decoder->FrameCount());
+    EXPECT_FALSE(decoder->DecodeFrameBufferAtIndex(0));
+  } else {
+    EXPECT_TRUE(decoder->IsSizeAvailable());
+    EXPECT_FALSE(decoder->Failed());
+    EXPECT_GT(decoder->FrameCount(), 0u);
+    ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+    ASSERT_TRUE(frame);
+    EXPECT_NE(ImageFrame::kFrameComplete, frame->GetStatus());
+    EXPECT_TRUE(decoder->Failed());
+  }
+}
+
+float HalfFloatToUnorm(uint16_t h) {
+  const uint32_t f = ((h & 0x8000) << 16) | (((h & 0x7c00) + 0x1c000) << 13) |
+                     ((h & 0x03ff) << 13);
+  return base::bit_cast<float>(f);
+}
+
+void ReadYUV(const char* file_name,
+             const gfx::Size& expected_y_size,
+             const gfx::Size& expected_uv_size,
+             SkColorType color_type,
+             int bit_depth,
+             gfx::Point3F* rgb_pixel = nullptr) {
+  scoped_refptr<SharedBuffer> data =
+      ReadFileToSharedBuffer("web_tests/images/resources/avif/", file_name);
+  ASSERT_TRUE(data);
+
+  auto decoder = CreateAVIFDecoder();
+  decoder->SetData(std::move(data), true);
+
+  ASSERT_TRUE(decoder->IsDecodedSizeAvailable());
+  ASSERT_TRUE(decoder->CanDecodeToYUV());
+  EXPECT_NE(decoder->GetYUVSubsampling(), cc::YUVSubsampling::kUnknown);
+  EXPECT_NE(decoder->GetYUVColorSpace(),
+            SkYUVColorSpace::kIdentity_SkYUVColorSpace);
+  EXPECT_EQ(decoder->GetYUVBitDepth(), bit_depth);
+
+  gfx::Size size = decoder->DecodedSize();
+  gfx::Size y_size = decoder->DecodedYUVSize(cc::YUVIndex::kY);
+  gfx::Size u_size = decoder->DecodedYUVSize(cc::YUVIndex::kU);
+  gfx::Size v_size = decoder->DecodedYUVSize(cc::YUVIndex::kV);
+
+  EXPECT_EQ(size, y_size);
+  EXPECT_EQ(u_size, v_size);
+
+  EXPECT_EQ(expected_y_size, y_size);
+  EXPECT_EQ(expected_uv_size, u_size);
+
+  wtf_size_t row_bytes[3];
+  row_bytes[0] = decoder->DecodedYUVWidthBytes(cc::YUVIndex::kY);
+  row_bytes[1] = decoder->DecodedYUVWidthBytes(cc::YUVIndex::kU);
+  row_bytes[2] = decoder->DecodedYUVWidthBytes(cc::YUVIndex::kV);
+
+  size_t planes_data_size = row_bytes[0] * y_size.height() +
+                            row_bytes[1] * u_size.height() +
+                            row_bytes[2] * v_size.height();
+  auto planes_data = std::make_unique<char[]>(planes_data_size);
+
+  void* planes[3];
+  planes[0] = planes_data.get();
+  planes[1] = static_cast<char*>(planes[0]) + row_bytes[0] * y_size.height();
+  planes[2] = static_cast<char*>(planes[1]) + row_bytes[1] * u_size.height();
+
+  decoder->SetImagePlanes(
+      std::make_unique<ImagePlanes>(planes, row_bytes, color_type));
+
+  decoder->DecodeToYUV();
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_TRUE(decoder->HasDisplayableYUVData());
+
+  auto metadata = decoder->MakeMetadataForDecodeAcceleration();
+  EXPECT_EQ(cc::ImageType::kAVIF, metadata.image_type);
+  EXPECT_EQ(size, metadata.image_size);
+  if (expected_y_size == expected_uv_size) {
+    EXPECT_EQ(cc::YUVSubsampling::k444, metadata.yuv_subsampling);
+  } else if (expected_y_size.height() == expected_uv_size.height()) {
+    EXPECT_EQ(cc::YUVSubsampling::k422, metadata.yuv_subsampling);
+  } else {
+    EXPECT_EQ(cc::YUVSubsampling::k420, metadata.yuv_subsampling);
+  }
+
+  if (!rgb_pixel) {
+    return;
+  }
+
+  if (bit_depth > 8) {
+    rgb_pixel->set_x(reinterpret_cast<uint16_t*>(planes[0])[0]);
+    rgb_pixel->set_y(reinterpret_cast<uint16_t*>(planes[1])[0]);
+    rgb_pixel->set_z(reinterpret_cast<uint16_t*>(planes[2])[0]);
+  } else {
+    rgb_pixel->set_x(reinterpret_cast<uint8_t*>(planes[0])[0]);
+    rgb_pixel->set_y(reinterpret_cast<uint8_t*>(planes[1])[0]);
+    rgb_pixel->set_z(reinterpret_cast<uint8_t*>(planes[2])[0]);
+  }
+
+  if (color_type == kGray_8_SkColorType) {
+    const float max_channel = (1 << bit_depth) - 1;
+    rgb_pixel->set_x(rgb_pixel->x() / max_channel);
+    rgb_pixel->set_y(rgb_pixel->y() / max_channel);
+    rgb_pixel->set_z(rgb_pixel->z() / max_channel);
+  } else if (color_type == kA16_unorm_SkColorType) {
+    constexpr float kR16MaxChannel = 65535.0f;
+    rgb_pixel->set_x(rgb_pixel->x() / kR16MaxChannel);
+    rgb_pixel->set_y(rgb_pixel->y() / kR16MaxChannel);
+    rgb_pixel->set_z(rgb_pixel->z() / kR16MaxChannel);
+  } else {
+    DCHECK_EQ(color_type, kA16_float_SkColorType);
+    rgb_pixel->set_x(HalfFloatToUnorm(rgb_pixel->x()));
+    rgb_pixel->set_y(HalfFloatToUnorm(rgb_pixel->y()));
+    rgb_pixel->set_z(HalfFloatToUnorm(rgb_pixel->z()));
+  }
+
+  // Convert our YUV pixel to RGB to avoid an excessive amounts of test
+  // expectations. We otherwise need bit_depth * yuv_sampling * color_type.
+  gfx::ColorTransform::Options options;
+  options.src_bit_depth = bit_depth;
+  options.dst_bit_depth = bit_depth;
+  auto transform = gfx::ColorTransform::NewColorTransform(
+      reinterpret_cast<AVIFImageDecoder*>(decoder.get())
+          ->GetColorSpaceForTesting(),
+      gfx::ColorSpace(), options);
+  transform->Transform(rgb_pixel, 1);
+}
+
+void TestYUVRed(const char* file_name,
+                const gfx::Size& expected_uv_size,
+                SkColorType color_type = kGray_8_SkColorType,
+                int bit_depth = 8) {
+  SCOPED_TRACE(base::StringPrintf("file_name=%s, color_type=%d", file_name,
+                                  int{color_type}));
+
+  constexpr gfx::Size kRedYSize(3, 3);
+
+  gfx::Point3F decoded_pixel;
+  ASSERT_NO_FATAL_FAILURE(ReadYUV(file_name, kRedYSize, expected_uv_size,
+                                  color_type, bit_depth, &decoded_pixel));
+
+  // Allow the RGB value to be off by one step. 1/max_value is the minimum
+  // amount of error possible if error exists for integer sources.
+  //
+  // For half float values we have additional error from precision limitations,
+  // which gets worse at the extents of [-0.5, 1] -- which is the case for our R
+  // channel since we're using a pure red source.
+  //
+  // https://en.wikipedia.org/wiki/Half-precision_floating-point_format#Precision_limitations_on_decimal_values_in_[0,_1]
+  const double kMinError = 1.0 / ((1 << bit_depth) - 1);
+  const double kError = color_type == kA16_float_SkColorType
+                            ? kMinError + std::pow(2, -11)
+                            : kMinError;
+  EXPECT_NEAR(decoded_pixel.x(), 1, kError);     // R
+  EXPECT_NEAR(decoded_pixel.y(), 0, kMinError);  // G
+  EXPECT_NEAR(decoded_pixel.z(), 0, kMinError);  // B
+}
+
+void DecodeTask(const Vector<char>* data, base::RepeatingClosure* done) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+
+  scoped_refptr<SharedBuffer> data_copy = SharedBuffer::Create();
+  data_copy->Append(*data);
+  decoder->SetData(std::move(data_copy), true);
+
+  EXPECT_TRUE(decoder->IsSizeAvailable());
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(decoder->FrameCount(), 1u);
+  ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame->GetStatus());
+  EXPECT_FALSE(decoder->Failed());
+
+  done->Run();
+}
+
+void InspectImage(
+    const StaticColorCheckParam& param,
+    ImageDecoder::HighBitDepthDecodingOption high_bit_depth_option) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoderWithOptions(
+      param.alpha_option, high_bit_depth_option, param.color_behavior,
+      cc::AuxImage::kDefault, ImageDecoder::AnimationOption::kUnspecified);
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(param.path);
+  ASSERT_TRUE(data.get());
+#if FIXME_DISTINGUISH_LOSSY_OR_LOSSLESS
+  EXPECT_EQ(param.compression_format,
+            ImageDecoder::GetCompressionFormat(data, "image/avif"));
+#endif
+  decoder->SetData(std::move(data), true);
+  EXPECT_EQ(1u, decoder->FrameCount());
+  EXPECT_EQ(kAnimationNone, decoder->RepetitionCount());
+  EXPECT_EQ(param.bit_depth > 8, decoder->ImageIsHighBitDepth());
+  auto metadata = decoder->MakeMetadataForDecodeAcceleration();
+  EXPECT_EQ(cc::ImageType::kAVIF, metadata.image_type);
+  // TODO(wtc): Check metadata.yuv_subsampling.
+  ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame->GetStatus());
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(param.orientation, decoder->Orientation());
+  EXPECT_EQ(param.color_type == ColorType::kRgbA ||
+                param.color_type == ColorType::kMonoA,
+            frame->HasAlpha());
+  auto get_color_channel = [](SkColorChannel channel, SkColor color) {
+    switch (channel) {
+      case SkColorChannel::kR:
+        return SkColorGetR(color);
+      case SkColorChannel::kG:
+        return SkColorGetG(color);
+      case SkColorChannel::kB:
+        return SkColorGetB(color);
+      case SkColorChannel::kA:
+        return SkColorGetA(color);
+    }
+  };
+  auto color_difference = [get_color_channel](SkColorChannel channel,
+                                              SkColor color1,
+                                              SkColor color2) -> int {
+    return std::abs(static_cast<int>(get_color_channel(channel, color1)) -
+                    static_cast<int>(get_color_channel(channel, color2)));
+  };
+  for (const auto& expected : param.colors) {
+    const SkBitmap& bitmap = frame->Bitmap();
+    SkColor frame_color =
+        bitmap.getColor(expected.point.x(), expected.point.y());
+
+    EXPECT_LE(color_difference(SkColorChannel::kR, frame_color, expected.color),
+              param.color_threshold);
+    EXPECT_LE(color_difference(SkColorChannel::kG, frame_color, expected.color),
+              param.color_threshold);
+    EXPECT_LE(color_difference(SkColorChannel::kB, frame_color, expected.color),
+              param.color_threshold);
+    // TODO(ryoh): Create alpha_threshold field for alpha channels.
+    EXPECT_LE(color_difference(SkColorChannel::kA, frame_color, expected.color),
+              param.color_threshold);
+    if (param.color_type == ColorType::kMono ||
+        param.color_type == ColorType::kMonoA) {
+      EXPECT_EQ(SkColorGetR(frame_color), SkColorGetG(frame_color));
+      EXPECT_EQ(SkColorGetR(frame_color), SkColorGetB(frame_color));
+    }
+  }
+}
+
+void TestAvifBppHistogram(const char* image_name,
+                          const char* histogram_name = nullptr,
+                          base::HistogramBase::Sample32 sample = 0) {
+  TestBppHistogram(CreateAVIFDecoder, "Avif", image_name, histogram_name,
+                   sample);
+}
+
+struct AVIFImageParam {
+  const char* path;
+  size_t expected_frame_count;
+  int expected_repetition_count;
+};
+
+constexpr AVIFImageParam kAnimatedTestParams[] = {
+    // star-animated-8bpc.avif, star-animated-10bpc.avif, and
+    // star-animated-12bpc.avif contain an EditListBox whose `flags` field is
+    // equal to 0, meaning the edit list is not repeated. Therefore their
+    // `expected_repetition_count` is 0.
+    {"/images/resources/avif/star-animated-8bpc.avif", 5u, 0},
+    {"/images/resources/avif/star-animated-8bpc-with-alpha.avif", 5u,
+     kAnimationLoopInfinite},
+    {"/images/resources/avif/star-animated-10bpc.avif", 5u, 0},
+    {"/images/resources/avif/star-animated-10bpc-with-alpha.avif", 5u,
+     kAnimationLoopInfinite},
+    {"/images/resources/avif/star-animated-12bpc.avif", 5u, 0},
+    {"/images/resources/avif/star-animated-12bpc-with-alpha.avif", 5u,
+     kAnimationLoopInfinite},
+    {"/images/resources/avif/star-animated-8bpc-1-repetition.avif", 5u, 1},
+    {"/images/resources/avif/star-animated-8bpc-10-repetition.avif", 5u, 10},
+    {"/images/resources/avif/star-animated-8bpc-infinite-repetition.avif", 5u,
+     kAnimationLoopInfinite},
+};
+
+constexpr AVIFImageParam kStaticTestParams[] = {
+    {"/images/resources/avif/red-at-12-oclock-with-color-profile-lossy.avif", 1,
+     kAnimationNone},
+    {"/images/resources/avif/red-at-12-oclock-with-color-profile-8bpc.avif", 1,
+     kAnimationNone},
+    {"/images/resources/avif/red-at-12-oclock-with-color-profile-10bpc.avif", 1,
+     kAnimationNone},
+    {"/images/resources/avif/red-at-12-oclock-with-color-profile-12bpc.avif", 1,
+     kAnimationNone},
+    {"/images/resources/avif/tiger_3layer_1res.avif", 1, kAnimationNone},
+    {"/images/resources/avif/tiger_3layer_3res.avif", 1, kAnimationNone},
+    {"/images/resources/avif/tiger_420_8b_grid1x13.avif", 1, kAnimationNone},
+    {"/images/resources/avif/dice_444_10b_grid4x3.avif", 1, kAnimationNone},
+    {"/images/resources/avif/gracehopper_422_12b_grid2x4.avif", 1,
+     kAnimationNone},
+    {"/images/resources/avif/small-with-gainmap-iso.avif", 1, kAnimationNone},
+};
+
+using AVIFValidImagesTest = ::testing::TestWithParam<AVIFImageParam>;
+
+INSTANTIATE_TEST_SUITE_P(AnimatedAVIF,
+                         AVIFValidImagesTest,
+                         ::testing::ValuesIn(kAnimatedTestParams));
+
+INSTANTIATE_TEST_SUITE_P(StaticAVIF,
+                         AVIFValidImagesTest,
+                         ::testing::ValuesIn(kStaticTestParams));
+
+TEST_P(AVIFValidImagesTest, ByteByByteDecode) {
+  TestByteByByteDecode(&CreateAVIFDecoder, GetParam().path,
+                       GetParam().expected_frame_count,
+                       GetParam().expected_repetition_count);
+}
+
+TEST(AnimatedAVIFTests, HasMultipleSubImages) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/star-animated-8bpc.avif"),
+      true);
+  EXPECT_TRUE(decoder->ImageHasBothStillAndAnimatedSubImages());
+}
+
+TEST(StaticAVIFTests, DoesNotHaveMultipleSubImages) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/"
+                             "red-at-12-oclock-with-color-profile-8bpc.avif"),
+      true);
+  EXPECT_FALSE(decoder->ImageHasBothStillAndAnimatedSubImages());
+}
+
+TEST(StaticAVIFTests, HasTimingInformation) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/"
+                             "red-at-12-oclock-with-color-profile-8bpc.avif"),
+      true);
+  EXPECT_TRUE(!!decoder->DecodeFrameBufferAtIndex(0));
+
+  // libavif has placeholder values for timestamp and duration on still images,
+  // so any duration value is valid, but the timestamp should be zero.
+  EXPECT_EQ(base::TimeDelta(), decoder->FrameTimestampAtIndex(0));
+}
+
+TEST(AnimatedAVIFTests, HasTimingInformation) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/star-animated-8bpc.avif"),
+      true);
+
+  constexpr auto kDuration = base::Milliseconds(100);
+
+  EXPECT_TRUE(!!decoder->DecodeFrameBufferAtIndex(0));
+  EXPECT_EQ(base::TimeDelta(), decoder->FrameTimestampAtIndex(0));
+  EXPECT_EQ(kDuration, decoder->FrameDurationAtIndex(0));
+
+  EXPECT_TRUE(!!decoder->DecodeFrameBufferAtIndex(1));
+  EXPECT_EQ(kDuration, decoder->FrameTimestampAtIndex(1));
+  EXPECT_EQ(kDuration, decoder->FrameDurationAtIndex(1));
+}
+
+TEST(StaticAVIFTests, NoCrashWhenCheckingForMultipleSubImages) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  constexpr char kHeader[] = {0x00, 0x00, 0x00, 0x20, 0x66, 0x74, 0x79, 0x70};
+  auto buffer = SharedBuffer::Create();
+  buffer->Append(kHeader);
+  decoder->SetData(std::move(buffer), false);
+  EXPECT_FALSE(decoder->ImageHasBothStillAndAnimatedSubImages());
+}
+
+// TODO(ryoh): Add corrupted video tests.
+
+TEST(StaticAVIFTests, invalidImages) {
+  // Image data is truncated.
+  TestInvalidStaticImage(
+      "/images/resources/avif/"
+      "red-at-12-oclock-with-color-profile-truncated.avif",
+      ErrorPhase::kParse);
+  // Chunk size in AV1 frame header doesn't match the file size.
+  TestInvalidStaticImage(
+      "/images/resources/avif/"
+      "red-at-12-oclock-with-color-profile-with-wrong-frame-header.avif",
+      ErrorPhase::kDecode);
+}
+
+TEST(StaticAVIFTests, GetIsoGainmapInfoAndData) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(
+      "/images/resources/avif/small-with-gainmap-iso.avif");
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(decoder->Size(), gfx::Size(134, 100));
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_TRUE(has_gainmap);
+
+  // Check gainmap metadata.
+  constexpr double kEpsilon = 0.00001;
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[0], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[1], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[2], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[0], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[1], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[2], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[3], 1., kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[0], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[1], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[2], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[0], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[1], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[2], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[0], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[1], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[2], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fDisplayRatioSdr, 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fDisplayRatioHdr, std::exp2(1.4427), kEpsilon);
+
+  EXPECT_EQ(gainmap_info.fBaseImageType, SkGainmapInfo::BaseImageType::kSDR);
+
+  EXPECT_EQ(gainmap_info.fGainmapMathColorSpace, nullptr);
+
+  // Check that the gainmap can be decoded.
+  std::unique_ptr<ImageDecoder> gainmap_decoder = CreateGainMapAVIFDecoder();
+  gainmap_decoder->SetData(gainmap_data, true);
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(gainmap_decoder->Size(), gfx::Size(33, 25));
+  ImageFrame* gainmap_frame = gainmap_decoder->DecodeFrameBufferAtIndex(0);
+  EXPECT_TRUE(gainmap_frame);
+}
+
+TEST(StaticAVIFTests, GetIsoGainmapInfoAndDataHdrToSdr) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(
+      "/images/resources/avif/small-with-gainmap-iso-hdrbase.avif");
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(decoder->Size(), gfx::Size(134, 100));
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_TRUE(has_gainmap);
+
+  // Check gainmap metadata.
+  constexpr double kEpsilon = 0.00001;
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[0], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[1], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[2], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMin[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[0], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[1], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[2], std::exp2(1.4427), kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapRatioMax[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[0], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[1], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[2], 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fGainmapGamma[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[0], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[1], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[2], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonSdr[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[0], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[1], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[2], 0.015625, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fEpsilonHdr[3], 1.0, kEpsilon);
+
+  EXPECT_NEAR(gainmap_info.fDisplayRatioSdr, 1.0, kEpsilon);
+  EXPECT_NEAR(gainmap_info.fDisplayRatioHdr, std::exp2(1.4427), kEpsilon);
+
+  EXPECT_EQ(gainmap_info.fBaseImageType, SkGainmapInfo::BaseImageType::kHDR);
+
+  // Check that the gainmap can be decoded.
+  std::unique_ptr<ImageDecoder> gainmap_decoder = CreateGainMapAVIFDecoder();
+  gainmap_decoder->SetData(gainmap_data, true);
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(gainmap_decoder->Size(), gfx::Size(33, 25));
+  ImageFrame* gainmap_frame = gainmap_decoder->DecodeFrameBufferAtIndex(0);
+  EXPECT_TRUE(gainmap_frame);
+}
+
+TEST(StaticAVIFTests, GetIsoGainmapColorSpaceSameICC) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  // The image has use_base_color_space set to false (i.e. use the alternate
+  // image's color space), and the base and alternate image ICC profiles are the
+  // same, so the alternate image color space should be ignored.
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(
+      "/images/resources/avif/small-with-gainmap-iso-usealtcolorspace.avif");
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_TRUE(has_gainmap);
+
+  EXPECT_EQ(gainmap_info.fGainmapMathColorSpace, nullptr);
+}
+
+void ExpectMatrixNear(const skcms_Matrix3x3& lhs,
+                      const skcms_Matrix3x3& rhs,
+                      float epsilon) {
+  for (int r = 0; r < 3; r++) {
+    for (int c = 0; c < 3; c++) {
+      EXPECT_NEAR(lhs.vals[r][c], rhs.vals[r][c], epsilon);
+    }
+  }
+}
+
+TEST(StaticAVIFTests, GetIsoGainmapColorSpaceDifferentICC) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  // The image has use_base_color_space set to false (i.e. use the alternate
+  // image's color space), and the base and alternate image ICC profiles are
+  // different, so the alternate ICC profile should be set as
+  // fGainmapMathColorSpace.
+  // Base is sRGB, alternate is P3.
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(
+      "/images/resources/avif/"
+      "small-with-gainmap-iso-usealtcolorspace-differenticc.avif");
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_TRUE(has_gainmap);
+
+  // Check that the gain map color space is specified.
+  EXPECT_NE(gainmap_info.fGainmapMathColorSpace, nullptr);
+  // Only compare the color primaries, the transfer function is irrelevant.
+  skcms_Matrix3x3 matrix;
+  ASSERT_TRUE(gainmap_info.fGainmapMathColorSpace->toXYZD50(&matrix));
+  ExpectMatrixNear(matrix, SkNamedGamut::kDisplayP3, 0.001);
+}
+
+TEST(StaticAVIFTests, GetIsoGainmapColorSpaceDifferentCICP) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  // The image has use_base_color_space set to false (i.e. use the alternate
+  // image's color space), and the base and alternate images don't have ICC
+  // but CICP values instead. The alternate image's CICP values should be used.
+  // Base is sRGB, alternate is Rec 2020.
+  scoped_refptr<SharedBuffer> data = ReadFileToSharedBuffer(
+      "/images/resources/avif/gainmap-sdr-srgb-to-hdr-wcg-rec2020.avif");
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_TRUE(has_gainmap);
+
+  // Check that the gain map color space is specified.
+  EXPECT_NE(gainmap_info.fGainmapMathColorSpace, nullptr);
+  // Only compare the color primaries, the transfer function is irrelevant.
+  skcms_Matrix3x3 matrix;
+  ASSERT_TRUE(gainmap_info.fGainmapMathColorSpace->toXYZD50(&matrix));
+  ExpectMatrixNear(matrix, SkNamedGamut::kRec2020, 0.0001);
+}
+
+TEST(StaticAVIFTests, GetGainmapInfoAndDataWithFeatureDisabled) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{},
+      /*disabled_features=*/{features::kAvifGainmapHdrImages});
+
+  const std::string image = "small-with-gainmap-iso.avif";
+  scoped_refptr<SharedBuffer> data =
+      ReadFileToSharedBuffer("web_tests/images/resources/avif", image.c_str());
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_FALSE(has_gainmap);
+
+  // Check that we get an error if we try decoding the gain map.
+  std::unique_ptr<ImageDecoder> gainmap_decoder = CreateGainMapAVIFDecoder();
+  gainmap_decoder->SetData(data, true);
+  EXPECT_FALSE(gainmap_decoder->IsSizeAvailable());
+  EXPECT_TRUE(gainmap_decoder->Failed());
+  EXPECT_EQ(gainmap_decoder->FrameCount(), 0u);
+  EXPECT_FALSE(gainmap_decoder->DecodeFrameBufferAtIndex(0));
+}
+
+TEST(StaticAVIFTests, GetGainmapInfoAndDataWithTruncatedData) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  const std::string image = "small-with-gainmap-iso.avif";
+  const Vector<char> data_vector =
+      ReadFile("web_tests/images/resources/avif", image.c_str());
+  scoped_refptr<SharedBuffer> half_data = SharedBuffer::Create(
+      base::span(data_vector).first(data_vector.size() / 2));
+
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(half_data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_FALSE(has_gainmap);
+}
+
+TEST(StaticAVIFTests, GetGainmapWithGammaZero) {
+  base::test::ScopedFeatureList scoped_feature_list;
+  scoped_feature_list.InitWithFeatures(
+      /*enabled_features=*/{features::kAvifGainmapHdrImages},
+      /*disabled_features=*/{});
+
+  const std::string image = "small-with-gainmap-iso-gammazero.avif";
+  scoped_refptr<SharedBuffer> data =
+      ReadFileToSharedBuffer("web_tests/images/resources/avif", image.c_str());
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(data, true);
+  SkGainmapInfo gainmap_info;
+  scoped_refptr<SegmentReader> gainmap_data;
+  const bool has_gainmap =
+      decoder->GetGainmapInfoAndData(gainmap_info, gainmap_data);
+  ASSERT_FALSE(has_gainmap);
+}
+
+TEST(StaticAVIFTests, YUV) {
+  // 3x3, YUV 4:2:0
+  constexpr gfx::Size kUVSize420(2, 2);
+  TestYUVRed("red-limited-range-420-8bpc.avif", kUVSize420);
+  TestYUVRed("red-full-range-420-8bpc.avif", kUVSize420);
+
+  // 3x3, YUV 4:2:2
+  constexpr gfx::Size kUVSize422(2, 3);
+  TestYUVRed("red-limited-range-422-8bpc.avif", kUVSize422);
+
+  // 3x3, YUV 4:4:4
+  constexpr gfx::Size kUVSize444(3, 3);
+  TestYUVRed("red-limited-range-444-8bpc.avif", kUVSize444);
+
+  // Full range BT709 color space is uncommon, but should be supported.
+  TestYUVRed("red-full-range-bt709-444-8bpc.avif", kUVSize444);
+
+  for (const auto ct : {kA16_unorm_SkColorType, kA16_float_SkColorType}) {
+    // 3x3, YUV 4:2:0, 10bpc
+    TestYUVRed("red-limited-range-420-10bpc.avif", kUVSize420, ct, 10);
+
+    // 3x3, YUV 4:2:2, 10bpc
+    TestYUVRed("red-limited-range-422-10bpc.avif", kUVSize422, ct, 10);
+
+    // 3x3, YUV 4:4:4, 10bpc
+    TestYUVRed("red-limited-range-444-10bpc.avif", kUVSize444, ct, 10);
+
+    // 3x3, YUV 4:2:0, 12bpc
+    TestYUVRed("red-limited-range-420-12bpc.avif", kUVSize420, ct, 12);
+
+    // 3x3, YUV 4:2:2, 12bpc
+    TestYUVRed("red-limited-range-422-12bpc.avif", kUVSize422, ct, 12);
+
+    // 3x3, YUV 4:4:4, 12bpc
+    TestYUVRed("red-limited-range-444-12bpc.avif", kUVSize444, ct, 12);
+
+    // Various common color spaces should be supported.
+    TestYUVRed("red-full-range-bt2020-pq-444-10bpc.avif", kUVSize444, ct, 10);
+    TestYUVRed("red-full-range-bt2020-pq-444-12bpc.avif", kUVSize444, ct, 12);
+    TestYUVRed("red-full-range-bt2020-hlg-444-10bpc.avif", kUVSize444, ct, 10);
+    TestYUVRed("red-full-range-bt2020-hlg-444-12bpc.avif", kUVSize444, ct, 12);
+  }
+}
+
+TEST(StaticAVIFTests, SizeAvailableBeforeAllDataReceived) {
+  scoped_refptr<SharedBuffer> stream_buffer = WTF::SharedBuffer::Create();
+  scoped_refptr<SegmentReader> segment_reader =
+      SegmentReader::CreateFromSharedBuffer(stream_buffer);
+  std::unique_ptr<ImageDecoder> decoder = ImageDecoder::CreateByMimeType(
+      "image/avif", segment_reader, /*data_complete=*/false,
+      ImageDecoder::kAlphaPremultiplied, ImageDecoder::kDefaultBitDepth,
+      ColorBehavior::kTag, cc::AuxImage::kDefault,
+      Platform::GetMaxDecodedImageBytes(), SkISize::MakeEmpty(),
+      ImageDecoder::AnimationOption::kUnspecified);
+  EXPECT_FALSE(decoder->IsSizeAvailable());
+
+  Vector<char> data =
+      ReadFile("/images/resources/avif/red-limited-range-420-8bpc.avif");
+  stream_buffer->Append(data);
+  EXPECT_EQ(stream_buffer->size(), 318u);
+  decoder->SetData(stream_buffer, /*all_data_received=*/false);
+  // All bytes are appended so we should have size, even though we pass
+  // all_data_received=false.
+  EXPECT_TRUE(decoder->IsSizeAvailable());
+
+  decoder->SetData(stream_buffer, /*all_data_received=*/true);
+  EXPECT_TRUE(decoder->IsSizeAvailable());
+}
+
+TEST(StaticAVIFTests, ProgressiveDecoding) {
+  base::HistogramTester histogram_tester;
+  scoped_refptr<SharedBuffer> stream_buffer = WTF::SharedBuffer::Create();
+  scoped_refptr<SegmentReader> segment_reader =
+      SegmentReader::CreateFromSharedBuffer(stream_buffer);
+  std::unique_ptr<ImageDecoder> decoder = ImageDecoder::CreateByMimeType(
+      "image/avif", segment_reader, /*data_complete=*/false,
+      ImageDecoder::kAlphaPremultiplied, ImageDecoder::kDefaultBitDepth,
+      ColorBehavior::kTag, cc::AuxImage::kDefault,
+      Platform::GetMaxDecodedImageBytes(), SkISize::MakeEmpty(),
+      ImageDecoder::AnimationOption::kUnspecified);
+
+  Vector<char> data = ReadFile("/images/resources/avif/tiger_3layer_1res.avif");
+  ASSERT_EQ(data.size(), 70944u);
+
+  // This image has three layers. The first layer is 8299 bytes. Because of
+  // image headers and other overhead, if we pass exactly 8299 bytes to the
+  // decoder, the decoder does not have enough data to decode the first layer.
+  stream_buffer->Append(base::span(data).first(8299u));
+  decoder->SetData(stream_buffer, /*all_data_received=*/false);
+  EXPECT_TRUE(decoder->IsSizeAvailable());
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(decoder->FrameCount(), 1u);
+  histogram_tester.ExpectTotalCount("Blink.DecodedImage.AvifDensity.Count.02MP",
+                                    0);
+  ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_EQ(frame->GetStatus(), ImageFrame::kFrameEmpty);
+  EXPECT_FALSE(decoder->Failed());
+
+  // An additional 301 bytes are enough data for the decoder to decode the first
+  // layer. With progressive decoding, the frame buffer status will transition
+  // to ImageFrame::kFramePartial.
+  stream_buffer->Append(base::span(data).subspan(8299u, 301u));
+  decoder->SetData(stream_buffer, /*all_data_received=*/false);
+  EXPECT_FALSE(decoder->Failed());
+  frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_EQ(frame->GetStatus(), ImageFrame::kFramePartial);
+  EXPECT_FALSE(decoder->Failed());
+
+  base::HistogramTester::CountsMap expected_counts;
+  EXPECT_THAT(histogram_tester.GetTotalCountsForPrefix(
+                  "Blink.DecodedImage.AvifDensity.Count."),
+              testing::ContainerEq(expected_counts));
+
+  // Now send the rest of the data.
+  stream_buffer->Append(base::span(data).subspan(8299u + 301u, 62344u));
+  decoder->SetData(stream_buffer, /*all_data_received=*/true);
+  EXPECT_FALSE(decoder->Failed());
+  frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_EQ(frame->GetStatus(), ImageFrame::kFrameComplete);
+  EXPECT_FALSE(decoder->Failed());
+
+  constexpr int kImageArea = 1216 * 832;  // = 1011712
+  constexpr int kFileSize = 70944;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 56
+  histogram_tester.ExpectUniqueSample(
+      "Blink.DecodedImage.AvifDensity.Count.02MP", kSample, 1);
+  expected_counts["Blink.DecodedImage.AvifDensity.Count.02MP"] = 1;
+  EXPECT_THAT(histogram_tester.GetTotalCountsForPrefix(
+                  "Blink.DecodedImage.AvifDensity.Count."),
+              testing::ContainerEq(expected_counts));
+}
+
+TEST(StaticAVIFTests, IncrementalDecoding) {
+  base::HistogramTester histogram_tester;
+  scoped_refptr<SharedBuffer> stream_buffer = WTF::SharedBuffer::Create();
+  scoped_refptr<SegmentReader> segment_reader =
+      SegmentReader::CreateFromSharedBuffer(stream_buffer);
+  std::unique_ptr<ImageDecoder> decoder = ImageDecoder::CreateByMimeType(
+      "image/avif", segment_reader, /*data_complete=*/false,
+      ImageDecoder::kAlphaPremultiplied, ImageDecoder::kDefaultBitDepth,
+      ColorBehavior::kTag, cc::AuxImage::kDefault,
+      Platform::GetMaxDecodedImageBytes(), SkISize::MakeEmpty(),
+      ImageDecoder::AnimationOption::kUnspecified);
+
+  Vector<char> data =
+      ReadFile("/images/resources/avif/tiger_420_8b_grid1x13.avif");
+
+  constexpr int kImageArea = 1216 * 832;  // = 1011712
+  constexpr int kFileSize = 72257;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 57
+
+  struct Step {
+    size_t size;  // In bytes.
+    ImageFrame::Status status;
+    int num_decoded_rows;  // In pixels.
+  };
+  // There are 13 tiles. Tiles are as wide as the image and 64 pixels tall.
+  // |num_decoded_rows| may be odd due to an output pixel row missing the
+  // following upsampled decoded chroma row (belonging to the next tile).
+  const Step steps[] = {
+      {2000, ImageFrame::kFrameEmpty, 0},
+      // Decoding half of the bytes gives 6 tile rows.
+      {data.size() / 2, ImageFrame::kFramePartial, 6 * 64 - 1},
+      // Decoding all bytes but one gives 12 tile rows.
+      {data.size() - 1, ImageFrame::kFramePartial, 12 * 64 - 1},
+      // Decoding all bytes gives all 13 tile rows.
+      {data.size(), ImageFrame::kFrameComplete, 13 * 64}};
+  size_t previous_size = 0;
+  auto data_span = base::span(data);
+  for (const Step& step : steps) {
+    stream_buffer->Append(
+        data_span.subspan(previous_size, step.size - previous_size));
+    decoder->SetData(stream_buffer, step.status == ImageFrame::kFrameComplete);
+
+    EXPECT_EQ(decoder->FrameCount(), 1u);
+    ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+    ASSERT_TRUE(frame);
+    ASSERT_FALSE(decoder->Failed());
+    EXPECT_EQ(frame->GetStatus(), step.status);
+
+    const SkBitmap& bitmap = frame->Bitmap();
+    for (int y = 0; y < bitmap.height(); ++y) {
+      const uint32_t* row = bitmap.getAddr32(0, y);
+      const bool is_row_decoded = y < step.num_decoded_rows;
+      for (int x = 0; x < bitmap.width(); ++x) {
+        // The input image is opaque. Pixels outside the decoded area are fully
+        // transparent black pixels, with each channel value being 0.
+        const bool is_pixel_decoded = row[x] != 0x00000000u;
+        ASSERT_EQ(is_pixel_decoded, is_row_decoded);
+      }
+    }
+    previous_size = step.size;
+
+    base::HistogramTester::CountsMap expected_counts;
+    if (step.status == ImageFrame::kFrameComplete) {
+      histogram_tester.ExpectUniqueSample(
+          "Blink.DecodedImage.AvifDensity.Count.02MP", kSample, 1);
+      expected_counts["Blink.DecodedImage.AvifDensity.Count.02MP"] = 1;
+    }
+    EXPECT_THAT(histogram_tester.GetTotalCountsForPrefix(
+                    "Blink.DecodedImage.AvifDensity.Count."),
+                testing::ContainerEq(expected_counts));
+  }
+}
+
+// Reproduces crbug.com/1402841. Decodes a large AVIF image 104 times in
+// parallel from base::ThreadPool. Should not cause temporary deadlock of
+// base::ThreadPool.
+TEST(StaticAVIFTests, ParallelDecoding) {
+  // The base::test::TaskEnvironment constructor creates a base::ThreadPool
+  // instance with 4 foreground threads. The number 4 comes from the
+  // test::TaskEnvironment::kNumForegroundThreadPoolThreads constant.
+  base::test::TaskEnvironment task_environment;
+
+  // This test image is fast to decode (all neutral gray pixels) and its
+  // allocation size is large enough to cause
+  // media::PaintCanvasVideoRenderer::ConvertVideoFrameToRGBPixels() to pick
+  // n_tasks > 1 if AVIFImageDecoder did not pass disable_threading=true to it.
+  Vector<char> data = ReadFile("/images/resources/avif/gray1024x704.avif");
+
+  // Task timeout in tests is 30 seconds (see https://crrev.com/c/1949028).
+  // Four blocking tasks cause a temporary deadlock (1.2 seconds) of
+  // base::ThreadPool, so we need at least 30 / 1.2 * 4 = 100 decodes for the
+  // test to time out without the bug fix. We add a margin of 4 decodes, i.e.,
+  // (30 / 1.2 + 1) * 4 = 104.
+  const size_t n_decodes = 104;
+  base::WaitableEvent event;
+  base::RepeatingClosure barrier = base::BarrierClosure(
+      n_decodes,
+      base::BindOnce(&base::WaitableEvent::Signal, base::Unretained(&event)));
+
+  for (size_t i = 0; i < n_decodes; ++i) {
+    base::ThreadPool::PostTask(
+        FROM_HERE,
+        base::BindOnce(DecodeTask, base::Unretained(&data), &barrier));
+  }
+
+  event.Wait();
+}
+
+TEST(StaticAVIFTests, AlphaHasNoIspeProperty) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/green-no-alpha-ispe.avif"),
+      true);
+  EXPECT_FALSE(decoder->IsSizeAvailable());
+  EXPECT_TRUE(decoder->Failed());
+}
+
+TEST(StaticAVIFTests, UnsupportedTransferFunctionInColrProperty) {
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(ReadFileToSharedBuffer(
+                       "/images/resources/avif/red-unsupported-transfer.avif"),
+                   true);
+  EXPECT_FALSE(decoder->IsSizeAvailable());
+  EXPECT_TRUE(decoder->Failed());
+}
+
+TEST(StaticAVIFTests, ClapPropertyZeroOrigin) {
+  constexpr int kClapWidth = 200;
+  constexpr int kClapHeight = 50;
+  std::unique_ptr<ImageDecoder> decoder1 = CreateAVIFDecoder();
+  decoder1->SetData(
+      ReadFileToSharedBuffer("/images/resources/avif/red-and-purple-crop.avif"),
+      true);
+  ASSERT_TRUE(decoder1->IsSizeAvailable());
+  gfx::Size size1 = decoder1->Size();
+  ASSERT_EQ(size1.width(), kClapWidth);
+  ASSERT_EQ(size1.height(), kClapHeight);
+  ImageFrame* frame1 = decoder1->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame1);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame1->GetStatus());
+  EXPECT_FALSE(decoder1->Failed());
+  const SkBitmap& bitmap1 = frame1->Bitmap();
+
+  // The second image is the uncropped version of the first image.
+  std::unique_ptr<ImageDecoder> decoder2 = CreateAVIFDecoder();
+  decoder2->SetData(ReadFileToSharedBuffer(
+                        "/images/resources/avif/red-and-purple-and-blue.avif"),
+                    true);
+  ASSERT_TRUE(decoder2->IsSizeAvailable());
+  gfx::Size size2 = decoder2->Size();
+  ASSERT_EQ(size2.width(), 300);
+  ASSERT_EQ(size2.height(), 100);
+  ImageFrame* frame2 = decoder2->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame2);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame2->GetStatus());
+  EXPECT_FALSE(decoder2->Failed());
+  const SkBitmap& bitmap2 = frame2->Bitmap();
+
+  // Compare pixel data.
+  for (int row = 0; row < kClapHeight; ++row) {
+    for (int col = 0; col < kClapWidth; ++col) {
+      EXPECT_EQ(bitmap1.getColor(/*x=*/col, /*y=*/row),
+                bitmap2.getColor(/*x=*/col, /*y=*/row));
+    }
+  }
+}
+
+// Verifies that an invalid 'clap' (clean aperture) image property is handled by
+// ignoring the 'clap' property and showing the full image.
+TEST(StaticAVIFTests, InvalidClapPropertyHandling) {
+  // The first image has a valid 'clap' property. The full image has size
+  // 320x280. The clean aperture has size 180x100, located at (40, 80) of the
+  // full image.
+  //
+  // Since the origin of the clean aperture is not located at (0, 0), we treat
+  // the 'clap' property as invalid. So the full image is shown.
+  std::unique_ptr<ImageDecoder> decoder1 = CreateAVIFDecoder();
+  decoder1->SetData(ReadFileToSharedBuffer(
+                        "/images/resources/avif/blue-and-magenta-crop.avif"),
+                    true);
+  ASSERT_TRUE(decoder1->IsSizeAvailable());
+  gfx::Size size1 = decoder1->Size();
+  ASSERT_EQ(size1.width(), 320);
+  ASSERT_EQ(size1.height(), 280);
+  ImageFrame* frame1 = decoder1->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame1);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame1->GetStatus());
+  EXPECT_FALSE(decoder1->Failed());
+  const SkBitmap& bitmap1 = frame1->Bitmap();
+
+  // The second image is the same as the first image except that the 'clap'
+  // property is invalid. In this case the full image is shown.
+  std::unique_ptr<ImageDecoder> decoder2 = CreateAVIFDecoder();
+  decoder2->SetData(
+      ReadFileToSharedBuffer(
+          "/images/resources/avif/blue-and-magenta-crop-invalid.avif"),
+      true);
+  ASSERT_TRUE(decoder2->IsSizeAvailable());
+  gfx::Size size2 = decoder2->Size();
+  ASSERT_EQ(size2.width(), 320);
+  ASSERT_EQ(size2.height(), 280);
+  ImageFrame* frame2 = decoder2->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame2);
+  EXPECT_EQ(ImageFrame::kFrameComplete, frame2->GetStatus());
+  EXPECT_FALSE(decoder2->Failed());
+  const SkBitmap& bitmap2 = frame2->Bitmap();
+
+  // Compare pixel data.
+  for (int row = 0; row < size1.height(); ++row) {
+    for (int col = 0; col < size1.width(); ++col) {
+      EXPECT_EQ(bitmap1.getColor(/*x=*/col, /*y=*/row),
+                bitmap2.getColor(/*x=*/col, /*y=*/row));
+    }
+  }
+}
+
+TEST(StaticAVIFTests, BppHistogramSmall) {
+  constexpr int kImageArea = 768 * 512;  // = 393216
+  constexpr int kFileSize = 25724;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 52
+  TestAvifBppHistogram("/images/resources/avif/kodim03.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.0.4MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramSmall3x3) {
+  // The centi bpp = 318 * 100 * 8 / (3 * 3) ~= 28267, which is greater than the
+  // histogram's max value (1000), so this sample goes into the overflow bucket.
+  constexpr int kSample = 1000;
+  TestAvifBppHistogram("/images/resources/avif/red-full-range-420-8bpc.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.0.1MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramSmall900000) {
+  constexpr int kImageArea = 1200 * 750;  // = 900000
+  constexpr int kFileSize = 8144;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 7
+  TestAvifBppHistogram("/images/resources/avif/peach_900000.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.0.9MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramBig) {
+  constexpr int kImageArea = 4032 * 3024;  // = 12192768
+  constexpr int kFileSize = 88692;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 6
+  TestAvifBppHistogram("/images/resources/avif/bee.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.13MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramBig13000000) {
+  constexpr int kImageArea = 4000 * 3250;  // = 13000000
+  constexpr int kFileSize = 16725;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 1
+  TestAvifBppHistogram("/images/resources/avif/peach_13000000.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.13MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramHuge) {
+  constexpr int kImageArea = 4624 * 3472;  // = 16054528
+  constexpr int kFileSize = 20095;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 1
+  TestAvifBppHistogram("/images/resources/avif/peach.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.14+MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramHuge13000002) {
+  constexpr int kImageArea = 3961 * 3282;  // = 13000002
+  constexpr int kFileSize = 16379;
+  constexpr int kSample =
+      (kFileSize * 100 * 8 + kImageArea / 2) / kImageArea;  // = 1
+  TestAvifBppHistogram("/images/resources/avif/peach_13000002.avif",
+                       "Blink.DecodedImage.AvifDensity.Count.14+MP", kSample);
+}
+
+TEST(StaticAVIFTests, BppHistogramInvalid) {
+  base::HistogramTester histogram_tester;
+  std::unique_ptr<ImageDecoder> decoder = CreateAVIFDecoder();
+  decoder->SetData(
+      ReadFileToSharedBuffer(
+          "/images/resources/avif/"
+          "red-at-12-oclock-with-color-profile-with-wrong-frame-header.avif"),
+      true);
+  ASSERT_TRUE(decoder->IsSizeAvailable());
+  EXPECT_FALSE(decoder->Failed());
+  EXPECT_EQ(decoder->FrameCount(), 1u);
+  ImageFrame* frame = decoder->DecodeFrameBufferAtIndex(0);
+  ASSERT_TRUE(frame);
+  EXPECT_NE(ImageFrame::kFrameComplete, frame->GetStatus());
+  EXPECT_TRUE(decoder->Failed());
+  const base::HistogramTester::CountsMap empty_counts;
+  EXPECT_THAT(histogram_tester.GetTotalCountsForPrefix(
+                  "Blink.DecodedImage.AvifDensity.Count."),
+              testing::ContainerEq(empty_counts));
+}
+
+TEST(StaticAVIFTests, BppHistogram10bit) {
+  TestAvifBppHistogram("/images/resources/avif/red-full-range-420-10bpc.avif");
+}
+
+TEST(StaticAVIFTests, BppHistogramMonochrome) {
+  TestAvifBppHistogram("/images/resources/avif/silver-400-matrix-6.avif");
+}
+
+TEST(StaticAVIFTests, BppHistogramAlpha) {
+  TestAvifBppHistogram("/images/resources/avif/red-with-alpha-8bpc.avif");
+}
+
+TEST(StaticAVIFTests, BppHistogramAnimated) {
+  TestAvifBppHistogram("/images/resources/avif/star-animated-8bpc.avif");
+}
+
+using StaticAVIFColorTests = ::testing::TestWithParam<StaticColorCheckParam>;
+
+INSTANTIATE_TEST_SUITE_P(Parameterized,
+                         StaticAVIFColorTests,
+                         ::testing::ValuesIn(kTestParams));
+
+TEST_P(StaticAVIFColorTests, InspectImage) {
+  InspectImage(GetParam(), ImageDecoder::kDefaultBitDepth);
+}
+
+TEST_P(StaticAVIFColorTests, InspectImageHalfFloat) {
+  InspectImage(GetParam(), ImageDecoder::kHighBitDepthToHalfFloat);
+}
+
+}  // namespace
+
+}  // namespace blink
diff --git a/third_party/blink/renderer/platform/image-decoders/avif/gen_crabbyavif_wrapper.py b/third_party/blink/renderer/platform/image-decoders/avif/gen_crabbyavif_wrapper.py
new file mode 100644
index 0000000000000..82f1c0c3df73a
--- /dev/null
+++ b/third_party/blink/renderer/platform/image-decoders/avif/gen_crabbyavif_wrapper.py
@@ -0,0 +1,164 @@
+# Copyright 2024 The Chromium Authors
+# Use of this source code is governed by a BSD-style license that can be
+# found in the LICENSE file.
+"""Script to generate crabbyavif wrapper using the libavif wrapper as the base.
+
+When the libavif wrapper files (any of avif_image_decoder*) are changed, this
+script must be run to update the crabbyavif wrappers
+(crabbyavif_image_decoder*).
+"""
+
+import os
+import re
+
+
+def _read_file(filename):
+    with open(filename) as file:
+        return file.read()
+
+
+def _write_file(filename, contents):
+    with open(filename, "w") as file:
+        file.write(contents)
+
+
+def _apply_replacements(contents, replacements):
+    for find, replace in replacements:
+        contents = re.sub(find, replace, contents)
+    return contents
+
+
+_COMMON_REPLACEMENTS = (
+    (r"Copyright 2020", "Copyright 2024"),
+    (r"third_party/libavif/src", "third_party/crabbyavif/src"),
+    (r"avif_image_decoder.h", "crabbyavif_image_decoder.h"),
+    (r"AVIFImageDecoder", "CrabbyAVIFImageDecoder"),
+    (r"AVIF_TRUE", "CRABBY_AVIF_TRUE"),
+    (r"AVIF_FALSE", "CRABBY_AVIF_FALSE"),
+    (r"AVIF_REPETITION_COUNT_", "CRABBY_AVIF_REPETITION_COUNT_"),
+)
+
+_NOTICE = """// WARNING: Auto-generated by gen_crabbyavif_wrapper.py.
+// Do not modify manually.
+"""
+
+
+def _generate_crabbyavif_file(source_file, replacements):
+    contents = _read_file(source_file)
+    contents = _apply_replacements(contents, _COMMON_REPLACEMENTS)
+    contents = _apply_replacements(contents, replacements)
+    contents = contents.split("\n")
+    # Copyright notice is 3 lines, insert the notice as the 4th line.
+    contents.insert(3, _NOTICE)
+    contents = "\n".join(contents)
+    crabby_source_file = "crabby%(source_file)s" % locals()
+    _write_file(crabby_source_file, contents)
+    os.system("clang-format -style chromium -i %(crabby_source_file)s" %
+              locals())
+
+
+_HEADER_REPLACEMENTS = (
+    (r"AVIF_AVIF_IMAGE_DECODER_H_", "AVIF_CRABBYAVIF_IMAGE_DECODER_H_"),
+    (r"AVIF_PIXEL_FORMAT_NONE", "crabbyavif::AVIF_PIXEL_FORMAT_NONE"),
+    # Functions
+    (r"avifDecoderDestroy", "crabbyavif::crabby_avifDecoderDestroy"),
+    (r"avifImageDestroy", "crabbyavif::crabby_avifImageDestroy"),
+    # Types
+    (r"avifIO", "crabbyavif::avifIO"),
+    (r"avifPixelFormat", "crabbyavif::avifPixelFormat"),
+    (r"avifROData", "crabbyavif::avifROData"),
+    (r"avifResult", "crabbyavif::avifResult"),
+    (r"\bavifDecoder\b", "crabbyavif::avifDecoder"),
+    (r"\bavifImage\b", "crabbyavif::avifImage"),
+)
+
+_CC_REPLACEMENTS = (
+    # Functions (to be namespaced and prefixed with "crabby_")
+    (
+        r"\bavifCropRectConvertCleanApertureBox\b",
+        "crabbyavif::crabby_avifCropRectConvertCleanApertureBox",
+    ),
+    (r"\bavifDecoderCreate\b", "crabbyavif::crabby_avifDecoderCreate"),
+    (
+        r"\bavifDecoderDecodedRowCount\b",
+        "crabbyavif::crabby_avifDecoderDecodedRowCount",
+    ),
+    (r"\bavifDecoderDestroy\b", "crabbyavif::crabby_avifDecoderDestroy"),
+    (r"\bavifDecoderNthImage\b", "crabbyavif::crabby_avifDecoderNthImage"),
+    (
+        r"\bavifDecoderNthImageMaxExtent\b",
+        "crabbyavif::crabby_avifDecoderNthImageMaxExtent",
+    ),
+    (
+        r"\bavifDecoderNthImageMaxExtent\b",
+        "crabbyavif::crabby_avifDecoderNthImageMaxExtent",
+    ),
+    (
+        r"\bavifDecoderNthImageTiming\b",
+        "crabbyavif::crabby_avifDecoderNthImageTiming",
+    ),
+    (r"\bavifDecoderParse\b", "crabbyavif::crabby_avifDecoderParse"),
+    (r"\bavifDecoderSetIO\b", "crabbyavif::crabby_avifDecoderSetIO"),
+    (r"\bavifDecoderSetSource\b", "crabbyavif::crabby_avifDecoderSetSource"),
+    (
+        r"\bavifGetPixelFormatInfo\b",
+        "crabbyavif::crabby_avifGetPixelFormatInfo",
+    ),
+    (r"\bavifImageCreateEmpty\b", "crabbyavif::crabby_avifImageCreateEmpty"),
+    (r"\bavifImageDestroy\b", "crabbyavif::crabby_avifImageDestroy"),
+    (r"\bavifImageSetViewRect\b", "crabbyavif::crabby_avifImageSetViewRect"),
+    (r"\bavifImageYUVToRGB\b", "crabbyavif::crabby_avifImageYUVToRGB"),
+    (
+        r"\bavifPeekCompatibleFileType\b",
+        "crabbyavif::crabby_avifPeekCompatibleFileType",
+    ),
+    (
+        r"\bavifRGBImageSetDefaults\b",
+        "crabbyavif::crabby_avifRGBImageSetDefaults",
+    ),
+    (r"\bavifResultToString\b", "crabbyavif::crabby_avifResultToString"),
+    # Symbols (to be namespaced).
+    (r"avifBool\b", "crabbyavif::avifBool"),
+    (r"avifColorPrimaries\b", "crabbyavif::avifColorPrimaries"),
+    (r"avifCropRect\b", "crabbyavif::avifCropRect"),
+    (r"avifDecoder\b", "crabbyavif::avifDecoder"),
+    (r"avifDiagnostics\b", "crabbyavif::avifDiagnostics"),
+    (r"avifExtent\b", "crabbyavif::avifExtent"),
+    (r"avifGainMap\b", "crabbyavif::avifGainMap"),
+    (r"avifGainMapMetadata\b", "crabbyavif::avifGainMapMetadata"),
+    (r"avifIO\b", "crabbyavif::avifIO"),
+    (r"avifImage\b", "crabbyavif::avifImage"),
+    (r"avifImageTiming\b", "crabbyavif::avifImageTiming"),
+    (r"avifMatrixCoefficients\b", "crabbyavif::avifMatrixCoefficients"),
+    (r"avifPixelFormatInfo\b", "crabbyavif::avifPixelFormatInfo"),
+    (r"avifRGBImage\b", "crabbyavif::avifRGBImage"),
+    (r"avifROData\b", "crabbyavif::avifROData"),
+    (r"avifRange\b", "crabbyavif::avifRange"),
+    (r"avifResult\b", "crabbyavif::avifResult"),
+    (
+        r"avifTransferCharacteristics\b",
+        "crabbyavif::avifTransferCharacteristics",
+    ),
+    (r"\bAVIF_", "crabbyavif::AVIF_"),
+    (r"\bCRABBY_AVIF_", "crabbyavif::CRABBY_AVIF_"),
+)
+
+_TEST_REPLACEMENTS = (
+    (r"\bAVIFValidImagesTest\b", "CrabbyAVIFValidImagesTest"),
+    (r"\bAnimatedAVIFTests\b", "CrabbyAnimatedAVIFTests"),
+    (r"\bStaticAVIFColorTests\b", "CrabbyStaticAVIFColorTests"),
+    (r"\bStaticAVIFTests\b", "CrabbyStaticAVIFTests"),
+)
+
+_FUZZER_REPLACEMENTS = ((r"kAvifDecoder", "kCrabbyAvifDecoder"), )
+
+def main():
+    _generate_crabbyavif_file("avif_image_decoder.h", _HEADER_REPLACEMENTS)
+    _generate_crabbyavif_file("avif_image_decoder.cc", _CC_REPLACEMENTS)
+    _generate_crabbyavif_file("avif_image_decoder_test.cc", _TEST_REPLACEMENTS)
+    _generate_crabbyavif_file("avif_image_decoder_fuzzer.cc",
+                              _FUZZER_REPLACEMENTS)
+
+
+if __name__ == "__main__":
+    main()
diff --git a/third_party/blink/renderer/platform/image-decoders/image_decoder.cc b/third_party/blink/renderer/platform/image-decoders/image_decoder.cc
index 0cc5dfa276964..0523ccbd18509 100644
--- a/third_party/blink/renderer/platform/image-decoders/image_decoder.cc
+++ b/third_party/blink/renderer/platform/image-decoders/image_decoder.cc
@@ -52,6 +52,7 @@
 #include "ui/gfx/geometry/size_conversions.h"

 #if BUILDFLAG(ENABLE_AV1_DECODER)
+#include "third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h"
 #include "third_party/blink/renderer/platform/image-decoders/avif/crabbyavif_image_decoder.h"
 #endif

@@ -197,7 +198,9 @@ String SniffMimeTypeInternal(scoped_refptr<SegmentReader> reader) {
     return "image/bmp";
   }
 #if BUILDFLAG(ENABLE_AV1_DECODER)
-  if (CrabbyAVIFImageDecoder::MatchesAVIFSignature(fast_reader)) {
+  if (base::FeatureList::IsEnabled(blink::features::kCrabbyAvif)
+          ? CrabbyAVIFImageDecoder::MatchesAVIFSignature(fast_reader)
+          : AVIFImageDecoder::MatchesAVIFSignature(fast_reader)) {
     return "image/avif";
   }
 #endif
@@ -307,9 +310,15 @@ std::unique_ptr<ImageDecoder> ImageDecoder::CreateByMimeType(
                                                 max_decoded_bytes);
 #if BUILDFLAG(ENABLE_AV1_DECODER)
   } else if (mime_type == "image/avif") {
-    decoder = std::make_unique<CrabbyAVIFImageDecoder>(
-        alpha_option, high_bit_depth_decoding_option, color_behavior, aux_image,
-        max_decoded_bytes, animation_option);
+    if (base::FeatureList::IsEnabled(blink::features::kCrabbyAvif)) {
+      decoder = std::make_unique<CrabbyAVIFImageDecoder>(
+          alpha_option, high_bit_depth_decoding_option, color_behavior,
+          aux_image, max_decoded_bytes, animation_option);
+    } else {
+      decoder = std::make_unique<AVIFImageDecoder>(
+          alpha_option, high_bit_depth_decoding_option, color_behavior,
+          aux_image, max_decoded_bytes, animation_option);
+    }
 #endif
   }

diff --git a/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.cc b/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.cc
index 93805eafce9fd..d07cbcd599f15 100644
--- a/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.cc
+++ b/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.cc
@@ -5,6 +5,7 @@
 #include "third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h"

 #include "third_party/blink/renderer/platform/graphics/color_behavior.h"
+#include "third_party/blink/renderer/platform/image-decoders/avif/avif_image_decoder.h"
 #include "third_party/blink/renderer/platform/image-decoders/avif/crabbyavif_image_decoder.h"
 #include "third_party/blink/renderer/platform/image-decoders/bmp/bmp_image_decoder.h"
 #include "third_party/blink/renderer/platform/image-decoders/image_decoder.h"
@@ -72,6 +73,13 @@ std::unique_ptr<ImageDecoder> CreateImageDecoder(DecoderType decoder_type,
           /*max_decoded_bytes=*/fdp.ConsumeIntegral<uint32_t>(),
           /*offset=*/fdp.ConsumeIntegral<uint32_t>());
     }
+    case DecoderType::kAvifDecoder: {
+      return std::make_unique<AVIFImageDecoder>(
+          GetAlphaOption(fdp), GetHbdOption(fdp), GetColorBehavior(fdp),
+          GetAuxImageType(fdp),
+          /*max_decoded_bytes=*/fdp.ConsumeIntegral<uint32_t>(),
+          GetAnimationOption(fdp));
+    }
     case DecoderType::kCrabbyAvifDecoder: {
       return std::make_unique<CrabbyAVIFImageDecoder>(
           GetAlphaOption(fdp), GetHbdOption(fdp), GetColorBehavior(fdp),
diff --git a/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h b/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h
index f6ad7fe6b4c52..d1227387a9145 100644
--- a/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h
+++ b/third_party/blink/renderer/platform/image-decoders/image_decoder_fuzzer_utils.h
@@ -15,6 +15,7 @@ enum class DecoderType {
   kBmpDecoder,
   kJpegDecoder,
   kPngDecoder,
+  kAvifDecoder,
   kCrabbyAvifDecoder,
 };

